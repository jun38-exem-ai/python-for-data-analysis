{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "469cbd60",
   "metadata": {},
   "source": [
    "### Chapter 10 인공 신경망 소개"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58d39ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import Perceptron\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "# 사용자 운영체제 확인\n",
    "import os\n",
    "os.name\n",
    "# 운영체제별 한글 폰트 설정\n",
    "if os.name == 'posix': # Mac 환경 폰트 설정\n",
    "    plt.rc('font', family='AppleGothic')\n",
    "elif os.name == 'nt': # Windows 환경 폰트 설정\n",
    "    plt.rc('font', family='Malgun Gothic')\n",
    "\n",
    "plt.rc('axes', unicode_minus=False) # 마이너스 폰트 설정\n",
    "\n",
    "\n",
    "# 글씨 선명하게 출력하는 설정\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "import os\n",
    "from matplotlib.colors import ListedColormap\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09f6176f",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = fetch_california_housing()\n",
    "\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(housing.data, housing.target, random_state=42)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_valid = scaler.transform(X_valid)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "194901f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = X_test[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41ee51e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=[8]),\n",
    "    keras.layers.Dense(30, activation=\"relu\"),\n",
    "    keras.layers.Dense(1)\n",
    "])   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b167427f",
   "metadata": {},
   "source": [
    "#### 조기종료 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d19b51d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "363/363 [==============================] - 1s 924us/step - loss: 1.5010 - val_loss: 0.9570\n",
      "Epoch 2/10\n",
      "363/363 [==============================] - 0s 691us/step - loss: 0.6885 - val_loss: 0.6370\n",
      "Epoch 3/10\n",
      "363/363 [==============================] - 0s 662us/step - loss: 0.6097 - val_loss: 0.5949\n",
      "Epoch 4/10\n",
      "363/363 [==============================] - 0s 690us/step - loss: 0.5637 - val_loss: 0.5383\n",
      "Epoch 5/10\n",
      "363/363 [==============================] - 0s 677us/step - loss: 0.5308 - val_loss: 0.5253\n",
      "Epoch 6/10\n",
      "363/363 [==============================] - 0s 682us/step - loss: 0.5061 - val_loss: 0.4905\n",
      "Epoch 7/10\n",
      "363/363 [==============================] - 0s 680us/step - loss: 0.4879 - val_loss: 0.4717\n",
      "Epoch 8/10\n",
      "363/363 [==============================] - 0s 725us/step - loss: 0.4739 - val_loss: 0.4493\n",
      "Epoch 9/10\n",
      "363/363 [==============================] - 0s 674us/step - loss: 0.4620 - val_loss: 0.4328\n",
      "Epoch 10/10\n",
      "363/363 [==============================] - 0s 673us/step - loss: 0.4521 - val_loss: 0.4217\n",
      "162/162 [==============================] - 0s 486us/step - loss: 0.4466\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(learning_rate=1e-3))\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_keras_model.h5\", save_best_only=True)\n",
    "history = model.fit(X_train, y_train, epochs=10,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[checkpoint_cb])\n",
    "model = keras.models.load_model(\"my_keras_model.h5\") # 최상의 모델로 롤백\n",
    "mse_test = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d71ce762",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "363/363 [==============================] - 0s 785us/step - loss: 0.4436 - val_loss: 0.4145\n",
      "Epoch 2/100\n",
      "363/363 [==============================] - 0s 671us/step - loss: 0.4364 - val_loss: 0.4071\n",
      "Epoch 3/100\n",
      "363/363 [==============================] - 0s 677us/step - loss: 0.4294 - val_loss: 0.4034\n",
      "Epoch 4/100\n",
      "363/363 [==============================] - 0s 686us/step - loss: 0.4243 - val_loss: 0.3965\n",
      "Epoch 5/100\n",
      "363/363 [==============================] - 0s 678us/step - loss: 0.4196 - val_loss: 0.3922\n",
      "Epoch 6/100\n",
      "363/363 [==============================] - 0s 715us/step - loss: 0.4149 - val_loss: 0.3883\n",
      "Epoch 7/100\n",
      "363/363 [==============================] - 0s 669us/step - loss: 0.4107 - val_loss: 0.3878\n",
      "Epoch 8/100\n",
      "363/363 [==============================] - 0s 712us/step - loss: 0.4070 - val_loss: 0.3864\n",
      "Epoch 9/100\n",
      "363/363 [==============================] - 0s 719us/step - loss: 0.4036 - val_loss: 0.3817\n",
      "Epoch 10/100\n",
      "363/363 [==============================] - 0s 661us/step - loss: 0.4005 - val_loss: 0.3777\n",
      "Epoch 11/100\n",
      "363/363 [==============================] - 0s 671us/step - loss: 0.3969 - val_loss: 0.3754\n",
      "Epoch 12/100\n",
      "363/363 [==============================] - 0s 640us/step - loss: 0.3944 - val_loss: 0.3769\n",
      "Epoch 13/100\n",
      "363/363 [==============================] - 0s 699us/step - loss: 0.3922 - val_loss: 0.3723\n",
      "Epoch 14/100\n",
      "363/363 [==============================] - 0s 682us/step - loss: 0.3895 - val_loss: 0.3692\n",
      "Epoch 15/100\n",
      "363/363 [==============================] - 0s 650us/step - loss: 0.3874 - val_loss: 0.3737\n",
      "Epoch 16/100\n",
      "363/363 [==============================] - 0s 708us/step - loss: 0.3854 - val_loss: 0.3646\n",
      "Epoch 17/100\n",
      "363/363 [==============================] - 0s 626us/step - loss: 0.3833 - val_loss: 0.3671\n",
      "Epoch 18/100\n",
      "363/363 [==============================] - 0s 663us/step - loss: 0.3816 - val_loss: 0.3691\n",
      "Epoch 19/100\n",
      "363/363 [==============================] - 0s 678us/step - loss: 0.3798 - val_loss: 0.3624\n",
      "Epoch 20/100\n",
      "363/363 [==============================] - 0s 722us/step - loss: 0.3782 - val_loss: 0.3619\n",
      "Epoch 21/100\n",
      "363/363 [==============================] - 0s 714us/step - loss: 0.3766 - val_loss: 0.3573\n",
      "Epoch 22/100\n",
      "363/363 [==============================] - 0s 811us/step - loss: 0.3751 - val_loss: 0.3563\n",
      "Epoch 23/100\n",
      "363/363 [==============================] - 0s 601us/step - loss: 0.3734 - val_loss: 0.3575\n",
      "Epoch 24/100\n",
      "363/363 [==============================] - 0s 699us/step - loss: 0.3721 - val_loss: 0.3561\n",
      "Epoch 25/100\n",
      "363/363 [==============================] - 0s 698us/step - loss: 0.3708 - val_loss: 0.3538\n",
      "Epoch 26/100\n",
      "363/363 [==============================] - 0s 649us/step - loss: 0.3697 - val_loss: 0.3554\n",
      "Epoch 27/100\n",
      "363/363 [==============================] - 0s 670us/step - loss: 0.3682 - val_loss: 0.3509\n",
      "Epoch 28/100\n",
      "363/363 [==============================] - 0s 594us/step - loss: 0.3672 - val_loss: 0.3513\n",
      "Epoch 29/100\n",
      "363/363 [==============================] - 0s 640us/step - loss: 0.3661 - val_loss: 0.3523\n",
      "Epoch 30/100\n",
      "363/363 [==============================] - 0s 601us/step - loss: 0.3652 - val_loss: 0.3543\n",
      "Epoch 31/100\n",
      "363/363 [==============================] - 0s 673us/step - loss: 0.3640 - val_loss: 0.3507\n",
      "Epoch 32/100\n",
      "363/363 [==============================] - 0s 669us/step - loss: 0.3630 - val_loss: 0.3480\n",
      "Epoch 33/100\n",
      "363/363 [==============================] - 0s 698us/step - loss: 0.3625 - val_loss: 0.3462\n",
      "Epoch 34/100\n",
      "363/363 [==============================] - 0s 638us/step - loss: 0.3612 - val_loss: 0.3489\n",
      "Epoch 35/100\n",
      "363/363 [==============================] - 0s 669us/step - loss: 0.3607 - val_loss: 0.3451\n",
      "Epoch 36/100\n",
      "363/363 [==============================] - 0s 688us/step - loss: 0.3599 - val_loss: 0.3440\n",
      "Epoch 37/100\n",
      "363/363 [==============================] - 0s 642us/step - loss: 0.3584 - val_loss: 0.3500\n",
      "Epoch 38/100\n",
      "363/363 [==============================] - 0s 633us/step - loss: 0.3581 - val_loss: 0.3510\n",
      "Epoch 39/100\n",
      "363/363 [==============================] - 0s 669us/step - loss: 0.3572 - val_loss: 0.3421\n",
      "Epoch 40/100\n",
      "363/363 [==============================] - 0s 637us/step - loss: 0.3564 - val_loss: 0.3464\n",
      "Epoch 41/100\n",
      "363/363 [==============================] - 0s 620us/step - loss: 0.3562 - val_loss: 0.3456\n",
      "Epoch 42/100\n",
      "363/363 [==============================] - 0s 651us/step - loss: 0.3554 - val_loss: 0.3541\n",
      "Epoch 43/100\n",
      "363/363 [==============================] - 0s 667us/step - loss: 0.3547 - val_loss: 0.3428\n",
      "Epoch 44/100\n",
      "363/363 [==============================] - 0s 655us/step - loss: 0.3538 - val_loss: 0.3454\n",
      "Epoch 45/100\n",
      "363/363 [==============================] - 0s 659us/step - loss: 0.3533 - val_loss: 0.3398\n",
      "Epoch 46/100\n",
      "363/363 [==============================] - 0s 642us/step - loss: 0.3528 - val_loss: 0.3528\n",
      "Epoch 47/100\n",
      "363/363 [==============================] - 0s 662us/step - loss: 0.3520 - val_loss: 0.3523\n",
      "Epoch 48/100\n",
      "363/363 [==============================] - 0s 637us/step - loss: 0.3510 - val_loss: 0.3432\n",
      "Epoch 49/100\n",
      "363/363 [==============================] - 0s 642us/step - loss: 0.3512 - val_loss: 0.3565\n",
      "Epoch 50/100\n",
      "363/363 [==============================] - 0s 675us/step - loss: 0.3508 - val_loss: 0.3364\n",
      "Epoch 51/100\n",
      "363/363 [==============================] - 0s 613us/step - loss: 0.3500 - val_loss: 0.3399\n",
      "Epoch 52/100\n",
      "363/363 [==============================] - 0s 643us/step - loss: 0.3492 - val_loss: 0.3410\n",
      "Epoch 53/100\n",
      "363/363 [==============================] - 0s 631us/step - loss: 0.3489 - val_loss: 0.3581\n",
      "Epoch 54/100\n",
      "363/363 [==============================] - 0s 607us/step - loss: 0.3483 - val_loss: 0.3442\n",
      "Epoch 55/100\n",
      "363/363 [==============================] - 0s 641us/step - loss: 0.3481 - val_loss: 0.3336\n",
      "Epoch 56/100\n",
      "363/363 [==============================] - 0s 800us/step - loss: 0.3473 - val_loss: 0.3349\n",
      "Epoch 57/100\n",
      "363/363 [==============================] - 0s 687us/step - loss: 0.3467 - val_loss: 0.3436\n",
      "Epoch 58/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3458 - val_loss: 0.3512\n",
      "Epoch 59/100\n",
      "363/363 [==============================] - 0s 703us/step - loss: 0.3462 - val_loss: 0.3466\n",
      "Epoch 60/100\n",
      "363/363 [==============================] - 0s 601us/step - loss: 0.3455 - val_loss: 0.3461\n",
      "Epoch 61/100\n",
      "363/363 [==============================] - 0s 870us/step - loss: 0.3447 - val_loss: 0.3485\n",
      "Epoch 62/100\n",
      "363/363 [==============================] - 0s 697us/step - loss: 0.3443 - val_loss: 0.3300\n",
      "Epoch 63/100\n",
      "363/363 [==============================] - 0s 670us/step - loss: 0.3440 - val_loss: 0.3354\n",
      "Epoch 64/100\n",
      "363/363 [==============================] - 0s 665us/step - loss: 0.3434 - val_loss: 0.3322\n",
      "Epoch 65/100\n",
      "363/363 [==============================] - 0s 619us/step - loss: 0.3426 - val_loss: 0.3431\n",
      "Epoch 66/100\n",
      "363/363 [==============================] - 0s 727us/step - loss: 0.3427 - val_loss: 0.3283\n",
      "Epoch 67/100\n",
      "363/363 [==============================] - 0s 670us/step - loss: 0.3420 - val_loss: 0.3466\n",
      "Epoch 68/100\n",
      "363/363 [==============================] - 0s 664us/step - loss: 0.3416 - val_loss: 0.3390\n",
      "Epoch 69/100\n",
      "363/363 [==============================] - 0s 677us/step - loss: 0.3414 - val_loss: 0.3358\n",
      "Epoch 70/100\n",
      "363/363 [==============================] - 0s 705us/step - loss: 0.3408 - val_loss: 0.3268\n",
      "Epoch 71/100\n",
      "363/363 [==============================] - 0s 654us/step - loss: 0.3402 - val_loss: 0.3570\n",
      "Epoch 72/100\n",
      "363/363 [==============================] - 0s 676us/step - loss: 0.3398 - val_loss: 0.3254\n",
      "Epoch 73/100\n",
      "363/363 [==============================] - 0s 674us/step - loss: 0.3394 - val_loss: 0.3297\n",
      "Epoch 74/100\n",
      "363/363 [==============================] - 0s 628us/step - loss: 0.3389 - val_loss: 0.3382\n",
      "Epoch 75/100\n",
      "363/363 [==============================] - 0s 734us/step - loss: 0.3384 - val_loss: 0.3356\n",
      "Epoch 76/100\n",
      "363/363 [==============================] - 0s 642us/step - loss: 0.3379 - val_loss: 0.3475\n",
      "Epoch 77/100\n",
      "363/363 [==============================] - 0s 645us/step - loss: 0.3377 - val_loss: 0.3309\n",
      "Epoch 78/100\n",
      "363/363 [==============================] - 0s 647us/step - loss: 0.3371 - val_loss: 0.3341\n",
      "Epoch 79/100\n",
      "363/363 [==============================] - 0s 690us/step - loss: 0.3366 - val_loss: 0.3362\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/100\n",
      "363/363 [==============================] - 0s 712us/step - loss: 0.3364 - val_loss: 0.3268\n",
      "Epoch 81/100\n",
      "363/363 [==============================] - 0s 629us/step - loss: 0.3359 - val_loss: 0.3355\n",
      "Epoch 82/100\n",
      "363/363 [==============================] - 0s 676us/step - loss: 0.3353 - val_loss: 0.3417\n",
      "162/162 [==============================] - 0s 439us/step - loss: 0.3413\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(learning_rate=1e-3))\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=10,\n",
    "                                                  restore_best_weights=True)\n",
    "history = model.fit(X_train, y_train, epochs=100,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[checkpoint_cb, early_stopping_cb])\n",
    "mse_test = model.evaluate(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e708fdba",
   "metadata": {},
   "source": [
    "#### 사용자 정의 콜백"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7effc876",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrintValTrainRatioCallback(keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        print(\"\\nval/train: {:.2f}\".format(logs[\"val_loss\"] / logs[\"loss\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2cce4b96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "307/363 [========================>.....] - ETA: 0s - loss: 0.3428\n",
      "val/train: 1.00\n",
      "363/363 [==============================] - 0s 645us/step - loss: 0.3393 - val_loss: 0.3389\n"
     ]
    }
   ],
   "source": [
    "val_train_ratio_cb = PrintValTrainRatioCallback()\n",
    "history = model.fit(X_train, y_train, epochs=1,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[val_train_ratio_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5297d37",
   "metadata": {},
   "source": [
    "### 텐서보드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1fd71358",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_logdir = os.path.join(os.curdir, \"my_logs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1cc4a270",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'.\\\\my_logs\\\\run_2022_04_15-10_24_13'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_run_logdir():\n",
    "    import time\n",
    "    run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")\n",
    "    return os.path.join(root_logdir, run_id)\n",
    "\n",
    "run_logdir = get_run_logdir()\n",
    "run_logdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1411eb6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "350573b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=[8]),\n",
    "    keras.layers.Dense(30, activation=\"relu\"),\n",
    "    keras.layers.Dense(1)\n",
    "])    \n",
    "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(learning_rate=1e-3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "db176f81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "363/363 [==============================] - 0s 795us/step - loss: 1.8866 - val_loss: 0.7126\n",
      "Epoch 2/30\n",
      "363/363 [==============================] - 0s 601us/step - loss: 0.6577 - val_loss: 0.6880\n",
      "Epoch 3/30\n",
      "363/363 [==============================] - 0s 713us/step - loss: 0.5934 - val_loss: 0.5803\n",
      "Epoch 4/30\n",
      "363/363 [==============================] - 0s 660us/step - loss: 0.5557 - val_loss: 0.5166\n",
      "Epoch 5/30\n",
      "363/363 [==============================] - 0s 670us/step - loss: 0.5272 - val_loss: 0.4895\n",
      "Epoch 6/30\n",
      "363/363 [==============================] - 0s 719us/step - loss: 0.5033 - val_loss: 0.4951\n",
      "Epoch 7/30\n",
      "363/363 [==============================] - 0s 632us/step - loss: 0.4854 - val_loss: 0.4861\n",
      "Epoch 8/30\n",
      "363/363 [==============================] - 0s 752us/step - loss: 0.4709 - val_loss: 0.4554\n",
      "Epoch 9/30\n",
      "363/363 [==============================] - 0s 649us/step - loss: 0.4578 - val_loss: 0.4413\n",
      "Epoch 10/30\n",
      "363/363 [==============================] - 0s 676us/step - loss: 0.4474 - val_loss: 0.4379\n",
      "Epoch 11/30\n",
      "363/363 [==============================] - 0s 639us/step - loss: 0.4393 - val_loss: 0.4396\n",
      "Epoch 12/30\n",
      "363/363 [==============================] - 0s 659us/step - loss: 0.4318 - val_loss: 0.4507\n",
      "Epoch 13/30\n",
      "363/363 [==============================] - 0s 662us/step - loss: 0.4261 - val_loss: 0.3997\n",
      "Epoch 14/30\n",
      "363/363 [==============================] - 0s 641us/step - loss: 0.4202 - val_loss: 0.3956\n",
      "Epoch 15/30\n",
      "363/363 [==============================] - 0s 663us/step - loss: 0.4155 - val_loss: 0.3916\n",
      "Epoch 16/30\n",
      "363/363 [==============================] - 0s 679us/step - loss: 0.4112 - val_loss: 0.3937\n",
      "Epoch 17/30\n",
      "363/363 [==============================] - 0s 656us/step - loss: 0.4077 - val_loss: 0.3809\n",
      "Epoch 18/30\n",
      "363/363 [==============================] - 0s 641us/step - loss: 0.4040 - val_loss: 0.3793\n",
      "Epoch 19/30\n",
      "363/363 [==============================] - 0s 666us/step - loss: 0.4004 - val_loss: 0.3850\n",
      "Epoch 20/30\n",
      "363/363 [==============================] - 0s 643us/step - loss: 0.3980 - val_loss: 0.3809\n",
      "Epoch 21/30\n",
      "363/363 [==============================] - 0s 647us/step - loss: 0.3949 - val_loss: 0.3701\n",
      "Epoch 22/30\n",
      "363/363 [==============================] - 0s 631us/step - loss: 0.3924 - val_loss: 0.3781\n",
      "Epoch 23/30\n",
      "363/363 [==============================] - 0s 647us/step - loss: 0.3898 - val_loss: 0.3650\n",
      "Epoch 24/30\n",
      "363/363 [==============================] - 0s 603us/step - loss: 0.3874 - val_loss: 0.3655\n",
      "Epoch 25/30\n",
      "363/363 [==============================] - 0s 678us/step - loss: 0.3851 - val_loss: 0.3611\n",
      "Epoch 26/30\n",
      "363/363 [==============================] - 0s 621us/step - loss: 0.3829 - val_loss: 0.3626\n",
      "Epoch 27/30\n",
      "363/363 [==============================] - 0s 673us/step - loss: 0.3809 - val_loss: 0.3564\n",
      "Epoch 28/30\n",
      "363/363 [==============================] - 0s 635us/step - loss: 0.3788 - val_loss: 0.3579\n",
      "Epoch 29/30\n",
      "363/363 [==============================] - 0s 657us/step - loss: 0.3769 - val_loss: 0.3561\n",
      "Epoch 30/30\n",
      "363/363 [==============================] - 0s 650us/step - loss: 0.3750 - val_loss: 0.3548\n"
     ]
    }
   ],
   "source": [
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
    "history = model.fit(X_train, y_train, epochs=30,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[checkpoint_cb, tensorboard_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "54235f8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-5b83ab61be3f2981\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-5b83ab61be3f2981\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir=./my_logs --port=6006"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56aaadf3",
   "metadata": {},
   "source": [
    "### 10.3 신경망 하이퍼파라미터 튜닝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c5e3127e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(n_hidden=1, n_neurons=30, learning_rate=3e-3, input_shape=[8]):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.InputLayer(input_shape=input_shape))\n",
    "    for layer in range(n_hidden):\n",
    "        model.add(keras.layers.Dense(n_neurons, activation=\"relu\"))\n",
    "    model.add(keras.layers.Dense(1))\n",
    "    optimizer = keras.optimizers.SGD(learning_rate=learning_rate)\n",
    "    model.compile(loss=\"mse\", optimizer=optimizer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0f45fb69",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\exem\\AppData\\Local\\Temp/ipykernel_8704/1709004121.py:1: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  keras_reg = keras.wrappers.scikit_learn.KerasRegressor(build_model)\n"
     ]
    }
   ],
   "source": [
    "keras_reg = keras.wrappers.scikit_learn.KerasRegressor(build_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cb91fd70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "363/363 [==============================] - 0s 741us/step - loss: 1.4901 - val_loss: 59.6889\n",
      "Epoch 2/100\n",
      "363/363 [==============================] - 0s 577us/step - loss: 1.0909 - val_loss: 0.5356\n",
      "Epoch 3/100\n",
      "363/363 [==============================] - 0s 599us/step - loss: 0.5441 - val_loss: 0.4837\n",
      "Epoch 4/100\n",
      "363/363 [==============================] - 0s 624us/step - loss: 0.4990 - val_loss: 0.4598\n",
      "Epoch 5/100\n",
      "363/363 [==============================] - 0s 626us/step - loss: 0.4765 - val_loss: 0.4264\n",
      "Epoch 6/100\n",
      "363/363 [==============================] - 0s 590us/step - loss: 0.4545 - val_loss: 0.4162\n",
      "Epoch 7/100\n",
      "363/363 [==============================] - 0s 686us/step - loss: 0.4452 - val_loss: 0.4020\n",
      "Epoch 8/100\n",
      "363/363 [==============================] - 0s 633us/step - loss: 0.4346 - val_loss: 0.3972\n",
      "Epoch 9/100\n",
      "363/363 [==============================] - 0s 609us/step - loss: 0.4258 - val_loss: 0.3973\n",
      "Epoch 10/100\n",
      "363/363 [==============================] - 0s 621us/step - loss: 0.4208 - val_loss: 0.3970\n",
      "Epoch 11/100\n",
      "363/363 [==============================] - 0s 618us/step - loss: 0.4152 - val_loss: 0.4016\n",
      "Epoch 12/100\n",
      "363/363 [==============================] - 0s 578us/step - loss: 0.4118 - val_loss: 0.4070\n",
      "Epoch 13/100\n",
      "363/363 [==============================] - 0s 652us/step - loss: 0.4080 - val_loss: 0.4141\n",
      "Epoch 14/100\n",
      "363/363 [==============================] - 0s 602us/step - loss: 0.4061 - val_loss: 0.4165\n",
      "Epoch 15/100\n",
      "363/363 [==============================] - 0s 627us/step - loss: 0.4027 - val_loss: 0.4185\n",
      "Epoch 16/100\n",
      "363/363 [==============================] - 0s 685us/step - loss: 0.3999 - val_loss: 0.4219\n",
      "Epoch 17/100\n",
      "363/363 [==============================] - 0s 644us/step - loss: 0.3964 - val_loss: 0.4266\n",
      "Epoch 18/100\n",
      "363/363 [==============================] - 0s 634us/step - loss: 0.3953 - val_loss: 0.4273\n",
      "Epoch 19/100\n",
      "363/363 [==============================] - 0s 668us/step - loss: 0.3918 - val_loss: 0.4270\n",
      "Epoch 20/100\n",
      "363/363 [==============================] - 0s 664us/step - loss: 0.3912 - val_loss: 0.4367\n",
      "162/162 [==============================] - 0s 478us/step - loss: 0.3837\n"
     ]
    }
   ],
   "source": [
    "keras_reg.fit(X_train, y_train, epochs=100,\n",
    "              validation_data=(X_valid, y_valid),\n",
    "              callbacks=[keras.callbacks.EarlyStopping(patience=10)])\n",
    "mse_test = keras_reg.score(X_test,y_test)\n",
    "y_pred = keras_reg.predict(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "195de2d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 913us/step - loss: 1.0712 - val_loss: 0.5093\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 666us/step - loss: 0.6589 - val_loss: 0.5636\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 678us/step - loss: 0.4816 - val_loss: 0.4047\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 654us/step - loss: 0.4334 - val_loss: 0.3908\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 661us/step - loss: 0.4276 - val_loss: 0.3923\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 905us/step - loss: 0.4183 - val_loss: 0.3860\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 721us/step - loss: 0.4113 - val_loss: 0.3791\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 688us/step - loss: 0.4095 - val_loss: 0.3773\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 644us/step - loss: 0.4024 - val_loss: 0.3780\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 657us/step - loss: 0.3998 - val_loss: 0.3606\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 668us/step - loss: 0.3971 - val_loss: 0.3794\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 661us/step - loss: 0.4082 - val_loss: 0.3818\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 662us/step - loss: 0.4033 - val_loss: 0.3652\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 660us/step - loss: 0.3930 - val_loss: 0.3583\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 662us/step - loss: 0.3869 - val_loss: 0.3583\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 661us/step - loss: 0.3838 - val_loss: 0.3576\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 663us/step - loss: 0.3820 - val_loss: 0.3624\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 673us/step - loss: 0.3976 - val_loss: 0.3613\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 703us/step - loss: 0.4110 - val_loss: 0.3615\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 643us/step - loss: 0.3826 - val_loss: 0.3553\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 714us/step - loss: 0.3780 - val_loss: 0.3598\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 651us/step - loss: 0.3772 - val_loss: 0.3587\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 712us/step - loss: 0.3779 - val_loss: 0.4011\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 737us/step - loss: 0.3841 - val_loss: 0.3618\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 668us/step - loss: 0.3730 - val_loss: 0.3643\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 675us/step - loss: 0.3727 - val_loss: 0.3565\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 738us/step - loss: 0.3898 - val_loss: 0.3700\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 732us/step - loss: 0.3822 - val_loss: 0.3610\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 707us/step - loss: 0.3727 - val_loss: 0.3506\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 688us/step - loss: 0.3701 - val_loss: 0.3542\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 658us/step - loss: 0.3690 - val_loss: 0.3509\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 669us/step - loss: 0.3694 - val_loss: 0.3495\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 730us/step - loss: 0.3675 - val_loss: 0.3510\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 721us/step - loss: 0.3679 - val_loss: 0.3514\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 694us/step - loss: 0.3677 - val_loss: 0.3521\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 706us/step - loss: 0.3664 - val_loss: 0.3525\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 768us/step - loss: 0.3676 - val_loss: 0.3480\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 678us/step - loss: 0.3694 - val_loss: 0.3523\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 694us/step - loss: 0.3670 - val_loss: 0.3534\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 728us/step - loss: 0.3662 - val_loss: 0.3480\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 670us/step - loss: 0.3696 - val_loss: 0.3581\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 679us/step - loss: 0.3654 - val_loss: 0.3474\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 734us/step - loss: 0.3658 - val_loss: 0.3491\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 722us/step - loss: 0.3645 - val_loss: 0.3485\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 702us/step - loss: 0.3652 - val_loss: 0.3463\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 739us/step - loss: 0.3642 - val_loss: 0.3554\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 667us/step - loss: 0.3646 - val_loss: 0.3476\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 722us/step - loss: 0.3659 - val_loss: 0.3519\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 710us/step - loss: 0.3642 - val_loss: 0.3472\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 656us/step - loss: 0.3653 - val_loss: 0.3478\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 763us/step - loss: 0.3641 - val_loss: 0.3726\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 728us/step - loss: 0.3646 - val_loss: 0.3492\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 681us/step - loss: 0.3644 - val_loss: 0.3471\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 686us/step - loss: 0.3647 - val_loss: 0.3559\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 741us/step - loss: 0.3639 - val_loss: 0.3524\n",
      "121/121 [==============================] - 0s 490us/step - loss: 0.3830\n",
      "[CV] END learning_rate=0.022174573948353458, n_hidden=1, n_neurons=4; total time=   9.5s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 908us/step - loss: 0.9309 - val_loss: 2.5427\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 661us/step - loss: 0.5014 - val_loss: 1.8994\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 742us/step - loss: 0.4483 - val_loss: 0.5512\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 754us/step - loss: 0.4361 - val_loss: 0.4523\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 659us/step - loss: 0.4288 - val_loss: 0.4196\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 710us/step - loss: 0.4293 - val_loss: 0.4151\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 767us/step - loss: 0.4248 - val_loss: 0.4459\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 702us/step - loss: 0.4246 - val_loss: 0.4027\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 724us/step - loss: 0.4203 - val_loss: 0.3931\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 766us/step - loss: 0.4211 - val_loss: 0.3895\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 647us/step - loss: 0.4176 - val_loss: 0.3919\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 928us/step - loss: 0.4171 - val_loss: 0.3976\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 711us/step - loss: 0.4173 - val_loss: 0.3988\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 723us/step - loss: 0.4190 - val_loss: 0.4085\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 775us/step - loss: 0.4175 - val_loss: 0.3866\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 701us/step - loss: 0.4133 - val_loss: 0.3884\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 751us/step - loss: 0.4156 - val_loss: 0.3870\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 778us/step - loss: 0.4166 - val_loss: 0.4274\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 729us/step - loss: 0.4154 - val_loss: 0.4189\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 701us/step - loss: 0.4138 - val_loss: 0.5174\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 687us/step - loss: 0.4157 - val_loss: 0.5172\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 775us/step - loss: 0.4151 - val_loss: 0.5919\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4135 - val_loss: 0.6372\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 815us/step - loss: 0.4128 - val_loss: 0.4144\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 768us/step - loss: 0.4125 - val_loss: 0.4235\n",
      "121/121 [==============================] - 0s 472us/step - loss: 0.4294\n",
      "[CV] END learning_rate=0.022174573948353458, n_hidden=1, n_neurons=4; total time=   4.8s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 993us/step - loss: 0.8645 - val_loss: 0.5069\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 727us/step - loss: 0.4860 - val_loss: 0.4205\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 745us/step - loss: 0.4444 - val_loss: 0.3948\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 698us/step - loss: 0.4314 - val_loss: 0.3961\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 760us/step - loss: 0.4302 - val_loss: 0.3958\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 740us/step - loss: 0.4275 - val_loss: 0.4047\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 721us/step - loss: 0.4287 - val_loss: 0.3943\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 708us/step - loss: 0.4284 - val_loss: 0.3982\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 736us/step - loss: 0.4279 - val_loss: 0.4037\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 736us/step - loss: 0.4319 - val_loss: 0.3998\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 777us/step - loss: 0.4256 - val_loss: 0.4069\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 723us/step - loss: 0.4240 - val_loss: 0.4084\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 727us/step - loss: 0.4251 - val_loss: 0.4085\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 713us/step - loss: 0.4234 - val_loss: 0.4090\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 757us/step - loss: 0.4237 - val_loss: 0.4062\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 782us/step - loss: 0.4236 - val_loss: 0.4105\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 764us/step - loss: 0.4214 - val_loss: 0.3994\n",
      "121/121 [==============================] - 0s 492us/step - loss: 0.4178\n",
      "[CV] END learning_rate=0.022174573948353458, n_hidden=1, n_neurons=4; total time=   3.3s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.1111 - val_loss: 12.8744\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7234 - val_loss: 4.4971\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 965us/step - loss: 0.5307 - val_loss: 0.4312\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 895us/step - loss: 0.4397 - val_loss: 0.4074\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 836us/step - loss: 0.4116 - val_loss: 0.3992\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 851us/step - loss: 0.3951 - val_loss: 0.4275\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 855us/step - loss: 0.3839 - val_loss: 0.4154\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 889us/step - loss: 0.3739 - val_loss: 0.4246\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3677 - val_loss: 0.4185\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3629 - val_loss: 0.4182\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3586 - val_loss: 0.3991\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3535 - val_loss: 0.3721\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 987us/step - loss: 0.3488 - val_loss: 0.3938\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3466 - val_loss: 0.4040\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3427 - val_loss: 0.3794\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 873us/step - loss: 0.3402 - val_loss: 0.3885\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 879us/step - loss: 0.3369 - val_loss: 0.3788\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 877us/step - loss: 0.3354 - val_loss: 0.3729\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 975us/step - loss: 0.3320 - val_loss: 0.3755\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 970us/step - loss: 0.3303 - val_loss: 0.3546\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 916us/step - loss: 0.3286 - val_loss: 0.3684\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 906us/step - loss: 0.3272 - val_loss: 0.3578\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 871us/step - loss: 0.3247 - val_loss: 0.3530\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 922us/step - loss: 0.3243 - val_loss: 0.3202\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 900us/step - loss: 0.3206 - val_loss: 0.3761\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 872us/step - loss: 0.3199 - val_loss: 0.3196\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 930us/step - loss: 0.3188 - val_loss: 0.3636\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 949us/step - loss: 0.3187 - val_loss: 0.3706\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 893us/step - loss: 0.3152 - val_loss: 0.3568\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 916us/step - loss: 0.3143 - val_loss: 0.3072\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 933us/step - loss: 0.3131 - val_loss: 0.3362\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 936us/step - loss: 0.3119 - val_loss: 0.3022\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 929us/step - loss: 0.3100 - val_loss: 0.3769\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 938us/step - loss: 0.3082 - val_loss: 0.3338\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 881us/step - loss: 0.3073 - val_loss: 0.3010\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 925us/step - loss: 0.3059 - val_loss: 0.4552\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 959us/step - loss: 0.3063 - val_loss: 0.3643\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 943us/step - loss: 0.3067 - val_loss: 0.3541\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 885us/step - loss: 0.3034 - val_loss: 0.3207\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 923us/step - loss: 0.3021 - val_loss: 0.3525\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 933us/step - loss: 0.3019 - val_loss: 0.3179\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 935us/step - loss: 0.3002 - val_loss: 0.3235\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 938us/step - loss: 0.2995 - val_loss: 0.3054\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 933us/step - loss: 0.2969 - val_loss: 0.3663\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 948us/step - loss: 0.2984 - val_loss: 0.2952\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 953us/step - loss: 0.2959 - val_loss: 0.3346\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 981us/step - loss: 0.2941 - val_loss: 0.3490\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 931us/step - loss: 0.2939 - val_loss: 0.3273\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2915 - val_loss: 0.2896\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 980us/step - loss: 0.2914 - val_loss: 0.3938\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 927us/step - loss: 0.2904 - val_loss: 0.3343\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 862us/step - loss: 0.2889 - val_loss: 0.3822\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 836us/step - loss: 0.2896 - val_loss: 0.2904\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 868us/step - loss: 0.2870 - val_loss: 0.3231\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 893us/step - loss: 0.2859 - val_loss: 0.3211\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 873us/step - loss: 0.2865 - val_loss: 0.2901\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 849us/step - loss: 0.2849 - val_loss: 0.4040\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 866us/step - loss: 0.2845 - val_loss: 0.3209\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 889us/step - loss: 0.2832 - val_loss: 0.2856\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 848us/step - loss: 0.2824 - val_loss: 0.3348\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 849us/step - loss: 0.2824 - val_loss: 0.3453\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 895us/step - loss: 0.2805 - val_loss: 0.3675\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 880us/step - loss: 0.2816 - val_loss: 0.2949\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 886us/step - loss: 0.2797 - val_loss: 0.4615\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 867us/step - loss: 0.2788 - val_loss: 0.2983\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 854us/step - loss: 0.2811 - val_loss: 0.2880\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 894us/step - loss: 0.2786 - val_loss: 0.4488\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 963us/step - loss: 0.2777 - val_loss: 0.3010\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 885us/step - loss: 0.2766 - val_loss: 0.4180\n",
      "121/121 [==============================] - 0s 565us/step - loss: 0.3093\n",
      "[CV] END learning_rate=0.005432590230265343, n_hidden=2, n_neurons=94; total time=  15.8s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9312 - val_loss: 0.6085\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 864us/step - loss: 0.5465 - val_loss: 0.6682\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 891us/step - loss: 0.4679 - val_loss: 0.7292\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 861us/step - loss: 0.4305 - val_loss: 0.6426\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 897us/step - loss: 0.4077 - val_loss: 0.4652\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 848us/step - loss: 0.3936 - val_loss: 0.3665\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 826us/step - loss: 0.3847 - val_loss: 0.4378\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 889us/step - loss: 0.3761 - val_loss: 0.5746\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 863us/step - loss: 0.3689 - val_loss: 0.8180\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 849us/step - loss: 0.3651 - val_loss: 0.7954\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 855us/step - loss: 0.3596 - val_loss: 0.8691\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 891us/step - loss: 0.3549 - val_loss: 0.8799\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 846us/step - loss: 0.3520 - val_loss: 1.0535\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 845us/step - loss: 0.3505 - val_loss: 1.0831\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 861us/step - loss: 0.3470 - val_loss: 1.0850\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 877us/step - loss: 0.3432 - val_loss: 1.1976\n",
      "121/121 [==============================] - 0s 507us/step - loss: 0.3663\n",
      "[CV] END learning_rate=0.005432590230265343, n_hidden=2, n_neurons=94; total time=   3.6s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0365 - val_loss: 0.6318\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 875us/step - loss: 0.5411 - val_loss: 6.4080\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 867us/step - loss: 0.4737 - val_loss: 18.2182\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 860us/step - loss: 0.7699 - val_loss: 7.2457\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 859us/step - loss: 0.4696 - val_loss: 2.3143\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 862us/step - loss: 0.4212 - val_loss: 1.6137\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 875us/step - loss: 0.4073 - val_loss: 0.7605\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 835us/step - loss: 0.3895 - val_loss: 0.4572\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 841us/step - loss: 0.3775 - val_loss: 0.3687\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 805us/step - loss: 0.3746 - val_loss: 0.3426\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 853us/step - loss: 0.3660 - val_loss: 0.4613\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 808us/step - loss: 0.3639 - val_loss: 0.3393\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 890us/step - loss: 0.3594 - val_loss: 0.3396\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 870us/step - loss: 0.3561 - val_loss: 0.4173\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 874us/step - loss: 0.3542 - val_loss: 0.3341\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 872us/step - loss: 0.3502 - val_loss: 0.4017\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 823us/step - loss: 0.3477 - val_loss: 0.3364\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 899us/step - loss: 0.3450 - val_loss: 0.3424\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 839us/step - loss: 0.3428 - val_loss: 0.3904\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 810us/step - loss: 0.3411 - val_loss: 0.3495\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 937us/step - loss: 0.3398 - val_loss: 0.3583\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 839us/step - loss: 0.3369 - val_loss: 0.3201\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 872us/step - loss: 0.3350 - val_loss: 0.3373\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 909us/step - loss: 0.3363 - val_loss: 0.3727\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 989us/step - loss: 0.3329 - val_loss: 0.3157\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 938us/step - loss: 0.3297 - val_loss: 0.3228\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 998us/step - loss: 0.3282 - val_loss: 0.3907\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 929us/step - loss: 0.3280 - val_loss: 0.3220\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3267 - val_loss: 0.4587\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 976us/step - loss: 0.3261 - val_loss: 0.3120\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3240 - val_loss: 0.3313\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 951us/step - loss: 0.3217 - val_loss: 0.3357\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 969us/step - loss: 0.3219 - val_loss: 0.3443\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 941us/step - loss: 0.3187 - val_loss: 0.3248\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 986us/step - loss: 0.3181 - val_loss: 0.3088\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 918us/step - loss: 0.3156 - val_loss: 0.4432\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 972us/step - loss: 0.3163 - val_loss: 0.4799\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 963us/step - loss: 0.3171 - val_loss: 0.5712\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 950us/step - loss: 0.3170 - val_loss: 0.3495\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 934us/step - loss: 0.3141 - val_loss: 0.4118\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 992us/step - loss: 0.3115 - val_loss: 0.3157\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 960us/step - loss: 0.3102 - val_loss: 0.3589\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 932us/step - loss: 0.3117 - val_loss: 0.3082\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3083 - val_loss: 0.3757\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 911us/step - loss: 0.3082 - val_loss: 0.3062\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 899us/step - loss: 0.3060 - val_loss: 0.3707\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 965us/step - loss: 0.3055 - val_loss: 0.3350\n",
      "Epoch 48/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 968us/step - loss: 0.3054 - val_loss: 0.3108\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 970us/step - loss: 0.3030 - val_loss: 0.3513\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 965us/step - loss: 0.3023 - val_loss: 0.3214\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 973us/step - loss: 0.3019 - val_loss: 0.3575\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 902us/step - loss: 0.3013 - val_loss: 0.3243\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 980us/step - loss: 0.3008 - val_loss: 0.3092\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 879us/step - loss: 0.2994 - val_loss: 0.3567\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 962us/step - loss: 0.2979 - val_loss: 0.3085\n",
      "121/121 [==============================] - 0s 582us/step - loss: 0.3041\n",
      "[CV] END learning_rate=0.005432590230265343, n_hidden=2, n_neurons=94; total time=  12.6s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.4708 - val_loss: 3.2118\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 817us/step - loss: 1.9535 - val_loss: 2.7756\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 819us/step - loss: 1.3686 - val_loss: 1.9687\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 834us/step - loss: 1.0923 - val_loss: 1.3376\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 854us/step - loss: 0.9489 - val_loss: 1.0036\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 853us/step - loss: 0.8692 - val_loss: 0.8735\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 843us/step - loss: 0.8220 - val_loss: 0.8014\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 914us/step - loss: 0.7912 - val_loss: 0.7688\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 814us/step - loss: 0.7692 - val_loss: 0.7488\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 815us/step - loss: 0.7518 - val_loss: 0.7332\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 880us/step - loss: 0.7372 - val_loss: 0.7218\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 813us/step - loss: 0.7244 - val_loss: 0.7081\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 818us/step - loss: 0.7124 - val_loss: 0.6995\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 911us/step - loss: 0.7014 - val_loss: 0.6887\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 845us/step - loss: 0.6909 - val_loss: 0.6760\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 863us/step - loss: 0.6808 - val_loss: 0.6691\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 875us/step - loss: 0.6713 - val_loss: 0.6580\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 834us/step - loss: 0.6620 - val_loss: 0.6519\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 856us/step - loss: 0.6531 - val_loss: 0.6426\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 840us/step - loss: 0.6445 - val_loss: 0.6359\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 860us/step - loss: 0.6363 - val_loss: 0.6233\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 870us/step - loss: 0.6281 - val_loss: 0.6172\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6203 - val_loss: 0.6098\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 940us/step - loss: 0.6127 - val_loss: 0.6050\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 929us/step - loss: 0.6056 - val_loss: 0.5943\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 893us/step - loss: 0.5985 - val_loss: 0.5828\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 884us/step - loss: 0.5916 - val_loss: 0.5803\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 877us/step - loss: 0.5852 - val_loss: 0.5681\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 980us/step - loss: 0.5788 - val_loss: 0.5635\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 869us/step - loss: 0.5727 - val_loss: 0.5578\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 870us/step - loss: 0.5668 - val_loss: 0.5519\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 877us/step - loss: 0.5611 - val_loss: 0.5436\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 852us/step - loss: 0.5556 - val_loss: 0.5384\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 866us/step - loss: 0.5503 - val_loss: 0.5312\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 810us/step - loss: 0.5452 - val_loss: 0.5247\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 900us/step - loss: 0.5403 - val_loss: 0.5217\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 863us/step - loss: 0.5355 - val_loss: 0.5134\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 889us/step - loss: 0.5308 - val_loss: 0.5120\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 879us/step - loss: 0.5264 - val_loss: 0.5054\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 913us/step - loss: 0.5222 - val_loss: 0.5005\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 867us/step - loss: 0.5179 - val_loss: 0.4984\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 959us/step - loss: 0.5140 - val_loss: 0.4920\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 881us/step - loss: 0.5102 - val_loss: 0.4877\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 953us/step - loss: 0.5064 - val_loss: 0.4849\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 878us/step - loss: 0.5029 - val_loss: 0.4820\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 890us/step - loss: 0.4995 - val_loss: 0.4776\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 979us/step - loss: 0.4962 - val_loss: 0.4737\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 974us/step - loss: 0.4931 - val_loss: 0.4699\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 906us/step - loss: 0.4900 - val_loss: 0.4669\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 900us/step - loss: 0.4871 - val_loss: 0.4648\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4842 - val_loss: 0.4610\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4815 - val_loss: 0.4569\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 905us/step - loss: 0.4789 - val_loss: 0.4539\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 848us/step - loss: 0.4763 - val_loss: 0.4513\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 920us/step - loss: 0.4739 - val_loss: 0.4489\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 841us/step - loss: 0.4715 - val_loss: 0.4458\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4692 - val_loss: 0.4439\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4671 - val_loss: 0.4409\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4649 - val_loss: 0.4386\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4628 - val_loss: 0.4363\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4609 - val_loss: 0.4342\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4589 - val_loss: 0.4324\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4571 - val_loss: 0.4304\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 884us/step - loss: 0.4553 - val_loss: 0.4286\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4535 - val_loss: 0.4268\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 917us/step - loss: 0.4518 - val_loss: 0.4251\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4501 - val_loss: 0.4234\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4485 - val_loss: 0.4224\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4469 - val_loss: 0.4204\n",
      "Epoch 70/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4453 - val_loss: 0.4187\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4439 - val_loss: 0.4174\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 961us/step - loss: 0.4424 - val_loss: 0.4164\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 893us/step - loss: 0.4411 - val_loss: 0.4146\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 902us/step - loss: 0.4397 - val_loss: 0.4133\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 904us/step - loss: 0.4384 - val_loss: 0.4125\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 824us/step - loss: 0.4371 - val_loss: 0.4109\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 847us/step - loss: 0.4359 - val_loss: 0.4100\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 801us/step - loss: 0.4347 - val_loss: 0.4092\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 907us/step - loss: 0.4335 - val_loss: 0.4081\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 904us/step - loss: 0.4323 - val_loss: 0.4070\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 948us/step - loss: 0.4312 - val_loss: 0.4060\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4301 - val_loss: 0.4069\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 965us/step - loss: 0.4290 - val_loss: 0.4057\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 919us/step - loss: 0.4280 - val_loss: 0.4048\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 891us/step - loss: 0.4270 - val_loss: 0.4028\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 886us/step - loss: 0.4259 - val_loss: 0.4027\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 985us/step - loss: 0.4250 - val_loss: 0.4011\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4240 - val_loss: 0.3992\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 929us/step - loss: 0.4231 - val_loss: 0.3981\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 903us/step - loss: 0.4221 - val_loss: 0.3984\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 908us/step - loss: 0.4213 - val_loss: 0.3962\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 981us/step - loss: 0.4204 - val_loss: 0.3958\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 928us/step - loss: 0.4196 - val_loss: 0.3952\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 910us/step - loss: 0.4187 - val_loss: 0.3942\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 844us/step - loss: 0.4179 - val_loss: 0.3937\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 856us/step - loss: 0.4171 - val_loss: 0.3937\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 799us/step - loss: 0.4163 - val_loss: 0.3926\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 851us/step - loss: 0.4155 - val_loss: 0.3916\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4147 - val_loss: 0.3934\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 862us/step - loss: 0.4140 - val_loss: 0.3911\n",
      "121/121 [==============================] - 0s 562us/step - loss: 0.4157\n",
      "[CV] END learning_rate=0.00037078874137762145, n_hidden=1, n_neurons=51; total time=  22.8s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.9270 - val_loss: 2.4520\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 936us/step - loss: 1.8991 - val_loss: 2.2557\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 967us/step - loss: 1.1826 - val_loss: 2.3686\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 902us/step - loss: 0.9124 - val_loss: 2.1668\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7991 - val_loss: 1.7788\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7427 - val_loss: 1.4096\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7096 - val_loss: 1.1143\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 913us/step - loss: 0.6873 - val_loss: 0.8920\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 898us/step - loss: 0.6705 - val_loss: 0.7469\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 856us/step - loss: 0.6566 - val_loss: 0.6569\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 902us/step - loss: 0.6444 - val_loss: 0.6102\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 975us/step - loss: 0.6334 - val_loss: 0.5986\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6233 - val_loss: 0.6161\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6138 - val_loss: 0.6517\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6047 - val_loss: 0.7050\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 967us/step - loss: 0.5961 - val_loss: 0.7691\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5879 - val_loss: 0.8408\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 880us/step - loss: 0.5801 - val_loss: 0.9148\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 836us/step - loss: 0.5726 - val_loss: 0.9908\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 921us/step - loss: 0.5656 - val_loss: 1.0599\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 885us/step - loss: 0.5588 - val_loss: 1.1355\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 913us/step - loss: 0.5524 - val_loss: 1.2020\n",
      "121/121 [==============================] - 0s 549us/step - loss: 0.5767\n",
      "[CV] END learning_rate=0.00037078874137762145, n_hidden=1, n_neurons=51; total time=   5.5s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.5600 - val_loss: 3.1834\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 905us/step - loss: 2.1072 - val_loss: 3.0084\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.2589 - val_loss: 2.0471\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 952us/step - loss: 0.9072 - val_loss: 1.4518\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 807us/step - loss: 0.7550 - val_loss: 0.9435\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 820us/step - loss: 0.6833 - val_loss: 0.7349\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 865us/step - loss: 0.6459 - val_loss: 0.6525\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 846us/step - loss: 0.6238 - val_loss: 0.6040\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 915us/step - loss: 0.6091 - val_loss: 0.5873\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5978 - val_loss: 0.5768\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5882 - val_loss: 0.5633\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 936us/step - loss: 0.5800 - val_loss: 0.5544\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5726 - val_loss: 0.5482\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5657 - val_loss: 0.5412\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 950us/step - loss: 0.5592 - val_loss: 0.5360\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5532 - val_loss: 0.5276\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5476 - val_loss: 0.5221\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 970us/step - loss: 0.5422 - val_loss: 0.5174\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 834us/step - loss: 0.5369 - val_loss: 0.5107\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 876us/step - loss: 0.5323 - val_loss: 0.5065\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5275 - val_loss: 0.5024\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 996us/step - loss: 0.5230 - val_loss: 0.4973\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 880us/step - loss: 0.5188 - val_loss: 0.4940\n",
      "Epoch 24/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 945us/step - loss: 0.5146 - val_loss: 0.4916\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 857us/step - loss: 0.5107 - val_loss: 0.4862\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5070 - val_loss: 0.4838\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5033 - val_loss: 0.4776\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 903us/step - loss: 0.4999 - val_loss: 0.4743\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 896us/step - loss: 0.4966 - val_loss: 0.4710\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 926us/step - loss: 0.4935 - val_loss: 0.4680\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 860us/step - loss: 0.4905 - val_loss: 0.4643\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 811us/step - loss: 0.4876 - val_loss: 0.4618\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 866us/step - loss: 0.4848 - val_loss: 0.4588\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 954us/step - loss: 0.4822 - val_loss: 0.4564\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 995us/step - loss: 0.4796 - val_loss: 0.4535\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4772 - val_loss: 0.4531\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 871us/step - loss: 0.4749 - val_loss: 0.4518\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 898us/step - loss: 0.4726 - val_loss: 0.4477\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4704 - val_loss: 0.4458\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4683 - val_loss: 0.4434\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 963us/step - loss: 0.4662 - val_loss: 0.4421\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 854us/step - loss: 0.4644 - val_loss: 0.4407\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 842us/step - loss: 0.4625 - val_loss: 0.4381\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 879us/step - loss: 0.4607 - val_loss: 0.4361\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 943us/step - loss: 0.4589 - val_loss: 0.4339\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 969us/step - loss: 0.4572 - val_loss: 0.4320\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 854us/step - loss: 0.4555 - val_loss: 0.4330\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 837us/step - loss: 0.4540 - val_loss: 0.4308\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 832us/step - loss: 0.4524 - val_loss: 0.4296\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 926us/step - loss: 0.4509 - val_loss: 0.4284\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4495 - val_loss: 0.4272\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 885us/step - loss: 0.4481 - val_loss: 0.4256\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 938us/step - loss: 0.4467 - val_loss: 0.4253\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 835us/step - loss: 0.4454 - val_loss: 0.4245\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 867us/step - loss: 0.4441 - val_loss: 0.4239\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 869us/step - loss: 0.4429 - val_loss: 0.4256\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 831us/step - loss: 0.4418 - val_loss: 0.4240\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 932us/step - loss: 0.4406 - val_loss: 0.4215\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4395 - val_loss: 0.4209\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4384 - val_loss: 0.4175\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 907us/step - loss: 0.4373 - val_loss: 0.4212\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 882us/step - loss: 0.4363 - val_loss: 0.4201\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 943us/step - loss: 0.4353 - val_loss: 0.4197\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 881us/step - loss: 0.4343 - val_loss: 0.4181\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4334 - val_loss: 0.4171\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4324 - val_loss: 0.4187\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4315 - val_loss: 0.4140\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 880us/step - loss: 0.4307 - val_loss: 0.4164\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 857us/step - loss: 0.4298 - val_loss: 0.4165\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 823us/step - loss: 0.4290 - val_loss: 0.4130\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 880us/step - loss: 0.4281 - val_loss: 0.4115\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 838us/step - loss: 0.4274 - val_loss: 0.4123\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 908us/step - loss: 0.4266 - val_loss: 0.4110\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 895us/step - loss: 0.4259 - val_loss: 0.4130\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 963us/step - loss: 0.4251 - val_loss: 0.4148\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4243 - val_loss: 0.4181\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 925us/step - loss: 0.4236 - val_loss: 0.4145\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 1000us/step - loss: 0.4230 - val_loss: 0.4135\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 998us/step - loss: 0.4223 - val_loss: 0.4140\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 900us/step - loss: 0.4216 - val_loss: 0.4151\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 897us/step - loss: 0.4210 - val_loss: 0.4122\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 867us/step - loss: 0.4203 - val_loss: 0.4129\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 832us/step - loss: 0.4197 - val_loss: 0.4138\n",
      "121/121 [==============================] - 0s 540us/step - loss: 0.4205\n",
      "[CV] END learning_rate=0.00037078874137762145, n_hidden=1, n_neurons=51; total time=  19.4s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.8463 - val_loss: 0.7853\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7045 - val_loss: 0.6113\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6125 - val_loss: 0.5509\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 894us/step - loss: 0.5632 - val_loss: 0.5097\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 934us/step - loss: 0.5267 - val_loss: 0.4804\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 969us/step - loss: 0.4976 - val_loss: 0.4602\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 978us/step - loss: 0.4749 - val_loss: 0.4366\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 952us/step - loss: 0.4568 - val_loss: 0.4352\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 930us/step - loss: 0.4423 - val_loss: 0.4284\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 930us/step - loss: 0.4306 - val_loss: 0.4123\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 978us/step - loss: 0.4210 - val_loss: 0.3994\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 875us/step - loss: 0.4129 - val_loss: 0.3916\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 971us/step - loss: 0.4063 - val_loss: 0.4010\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 971us/step - loss: 0.4009 - val_loss: 0.4138\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 927us/step - loss: 0.3961 - val_loss: 0.3963\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3920 - val_loss: 0.3991\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 999us/step - loss: 0.3880 - val_loss: 0.4059\n",
      "Epoch 18/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 976us/step - loss: 0.3849 - val_loss: 0.3921\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 910us/step - loss: 0.3813 - val_loss: 0.3926\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 930us/step - loss: 0.3791 - val_loss: 0.3902\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 902us/step - loss: 0.3765 - val_loss: 0.3947\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 908us/step - loss: 0.3740 - val_loss: 0.3871\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 953us/step - loss: 0.3718 - val_loss: 0.3883\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 964us/step - loss: 0.3699 - val_loss: 0.3676\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 974us/step - loss: 0.3678 - val_loss: 0.3876\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 970us/step - loss: 0.3663 - val_loss: 0.3636\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 926us/step - loss: 0.3647 - val_loss: 0.3878\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 903us/step - loss: 0.3629 - val_loss: 0.3835\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 993us/step - loss: 0.3612 - val_loss: 0.3880\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 933us/step - loss: 0.3601 - val_loss: 0.3592\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 903us/step - loss: 0.3583 - val_loss: 0.3564\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 970us/step - loss: 0.3572 - val_loss: 0.3523\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 945us/step - loss: 0.3557 - val_loss: 0.3733\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 921us/step - loss: 0.3546 - val_loss: 0.3664\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 964us/step - loss: 0.3536 - val_loss: 0.3468\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 903us/step - loss: 0.3522 - val_loss: 0.3813\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3513 - val_loss: 0.3375\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3502 - val_loss: 0.3874\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3492 - val_loss: 0.3400\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 934us/step - loss: 0.3484 - val_loss: 0.3755\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 990us/step - loss: 0.3472 - val_loss: 0.3523\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 972us/step - loss: 0.3461 - val_loss: 0.3419\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 907us/step - loss: 0.3460 - val_loss: 0.3408\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 902us/step - loss: 0.3443 - val_loss: 0.3783\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 897us/step - loss: 0.3444 - val_loss: 0.3458\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 971us/step - loss: 0.3429 - val_loss: 0.3515\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 900us/step - loss: 0.3422 - val_loss: 0.3670\n",
      "121/121 [==============================] - 0s 548us/step - loss: 0.3595\n",
      "[CV] END learning_rate=0.0016535051383872363, n_hidden=2, n_neurons=70; total time=  11.4s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.9782 - val_loss: 5.0617\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6889 - val_loss: 2.3610\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 912us/step - loss: 0.6165 - val_loss: 1.0309\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 968us/step - loss: 0.5665 - val_loss: 0.5489\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 902us/step - loss: 0.5268 - val_loss: 0.4856\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 933us/step - loss: 0.4966 - val_loss: 0.5139\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 901us/step - loss: 0.4731 - val_loss: 0.5770\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 921us/step - loss: 0.4547 - val_loss: 0.6327\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 967us/step - loss: 0.4400 - val_loss: 0.6046\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 909us/step - loss: 0.4289 - val_loss: 0.5854\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 891us/step - loss: 0.4192 - val_loss: 0.5381\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 932us/step - loss: 0.4113 - val_loss: 0.5281\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 905us/step - loss: 0.4053 - val_loss: 0.4919\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 899us/step - loss: 0.4000 - val_loss: 0.4130\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 894us/step - loss: 0.3953 - val_loss: 0.4007\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 909us/step - loss: 0.3909 - val_loss: 0.3736\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 969us/step - loss: 0.3870 - val_loss: 0.3630\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 915us/step - loss: 0.3839 - val_loss: 0.3605\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 949us/step - loss: 0.3801 - val_loss: 0.3565\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 967us/step - loss: 0.3773 - val_loss: 0.3571\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 907us/step - loss: 0.3751 - val_loss: 0.3632\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 901us/step - loss: 0.3724 - val_loss: 0.3641\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 963us/step - loss: 0.3699 - val_loss: 0.3931\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 905us/step - loss: 0.3679 - val_loss: 0.3878\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 969us/step - loss: 0.3660 - val_loss: 0.3969\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 905us/step - loss: 0.3641 - val_loss: 0.4112\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 925us/step - loss: 0.3614 - val_loss: 0.4147\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 886us/step - loss: 0.3605 - val_loss: 0.4291\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 963us/step - loss: 0.3583 - val_loss: 0.4809\n",
      "121/121 [==============================] - 0s 533us/step - loss: 0.3730\n",
      "[CV] END learning_rate=0.0016535051383872363, n_hidden=2, n_neurons=70; total time=   6.9s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.6453 - val_loss: 0.8517\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 895us/step - loss: 0.6887 - val_loss: 0.6281\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 977us/step - loss: 0.6167 - val_loss: 0.5772\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 904us/step - loss: 0.5728 - val_loss: 0.5441\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 965us/step - loss: 0.5368 - val_loss: 0.5219\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 940us/step - loss: 0.5081 - val_loss: 0.4934\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 910us/step - loss: 0.4841 - val_loss: 0.4580\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 930us/step - loss: 0.4651 - val_loss: 0.4344\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 928us/step - loss: 0.4493 - val_loss: 0.4790\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 884us/step - loss: 0.4372 - val_loss: 0.4088\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 887us/step - loss: 0.4261 - val_loss: 0.4806\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 858us/step - loss: 0.4178 - val_loss: 0.4078\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 911us/step - loss: 0.4104 - val_loss: 0.3889\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 948us/step - loss: 0.4045 - val_loss: 0.4726\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 897us/step - loss: 0.4006 - val_loss: 0.3745\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 984us/step - loss: 0.3955 - val_loss: 0.4777\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 966us/step - loss: 0.3932 - val_loss: 0.3705\n",
      "Epoch 18/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 957us/step - loss: 0.3893 - val_loss: 0.3931\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 899us/step - loss: 0.3867 - val_loss: 0.4320\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 921us/step - loss: 0.3839 - val_loss: 0.3774\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3817 - val_loss: 0.3899\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 944us/step - loss: 0.3800 - val_loss: 0.3633\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 817us/step - loss: 0.3778 - val_loss: 0.3616\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 850us/step - loss: 0.3753 - val_loss: 0.4437\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 930us/step - loss: 0.3750 - val_loss: 0.3567\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 869us/step - loss: 0.3725 - val_loss: 0.3589\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 917us/step - loss: 0.3703 - val_loss: 0.4744\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 909us/step - loss: 0.3706 - val_loss: 0.3505\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 925us/step - loss: 0.3679 - val_loss: 0.5349\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 962us/step - loss: 0.3684 - val_loss: 0.3535\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 909us/step - loss: 0.3653 - val_loss: 0.3753\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 965us/step - loss: 0.3638 - val_loss: 0.4497\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 907us/step - loss: 0.3629 - val_loss: 0.3898\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 902us/step - loss: 0.3614 - val_loss: 0.4557\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 930us/step - loss: 0.3620 - val_loss: 0.3423\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 946us/step - loss: 0.3590 - val_loss: 0.3654\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 955us/step - loss: 0.3591 - val_loss: 0.3443\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 995us/step - loss: 0.3573 - val_loss: 0.5512\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 906us/step - loss: 0.3577 - val_loss: 0.3395\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 936us/step - loss: 0.3551 - val_loss: 0.4527\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 965us/step - loss: 0.3547 - val_loss: 0.3819\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 988us/step - loss: 0.3532 - val_loss: 0.4148\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 995us/step - loss: 0.3527 - val_loss: 0.3539\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3519 - val_loss: 0.4505\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3520 - val_loss: 0.3386\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 940us/step - loss: 0.3498 - val_loss: 0.4286\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 954us/step - loss: 0.3496 - val_loss: 0.3624\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 955us/step - loss: 0.3491 - val_loss: 0.3524\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 901us/step - loss: 0.3471 - val_loss: 0.4309\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 960us/step - loss: 0.3472 - val_loss: 0.3631\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 972us/step - loss: 0.3459 - val_loss: 0.4144\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 957us/step - loss: 0.3459 - val_loss: 0.3600\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 987us/step - loss: 0.3452 - val_loss: 0.3298\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 920us/step - loss: 0.3443 - val_loss: 0.3288\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 950us/step - loss: 0.3432 - val_loss: 0.3296\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 900us/step - loss: 0.3422 - val_loss: 0.3760\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 896us/step - loss: 0.3421 - val_loss: 0.3946\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 938us/step - loss: 0.3422 - val_loss: 0.3463\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 925us/step - loss: 0.3409 - val_loss: 0.3679\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 911us/step - loss: 0.3406 - val_loss: 0.3271\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 948us/step - loss: 0.3399 - val_loss: 0.3427\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 915us/step - loss: 0.3389 - val_loss: 0.3846\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 954us/step - loss: 0.3393 - val_loss: 0.3299\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 905us/step - loss: 0.3384 - val_loss: 0.3547\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 943us/step - loss: 0.3381 - val_loss: 0.3454\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 990us/step - loss: 0.3373 - val_loss: 0.4410\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 894us/step - loss: 0.3376 - val_loss: 0.3736\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 979us/step - loss: 0.3367 - val_loss: 0.5446\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 979us/step - loss: 0.3372 - val_loss: 0.4240\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3366 - val_loss: 0.5486\n",
      "121/121 [==============================] - 0s 572us/step - loss: 0.3403\n",
      "[CV] END learning_rate=0.0016535051383872363, n_hidden=2, n_neurons=70; total time=  16.4s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 954us/step - loss: 1.7966 - val_loss: 953.4102\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 788us/step - loss: 9.0469 - val_loss: 2699.4617\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 809us/step - loss: 22.1545 - val_loss: 14889.6943\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 782us/step - loss: 54.1194 - val_loss: 56869.6641\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 830us/step - loss: 234.5744 - val_loss: 266096.6250\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 9950.6455 - val_loss: 1161427.5000\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 11840.8623 - val_loss: 5216512.0000\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 860us/step - loss: 174349.6094 - val_loss: 23341664.0000\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 844us/step - loss: 359990.7500 - val_loss: 105443608.0000\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 792us/step - loss: 4543938.0000 - val_loss: 515576928.0000\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 847us/step - loss: 8003564.5000 - val_loss: 2279391744.0000\n",
      "121/121 [==============================] - 0s 535us/step - loss: 6033576.5000\n",
      "[CV] END learning_rate=0.01824796188192035, n_hidden=0, n_neurons=40; total time=   2.5s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 953us/step - loss: 0.9061 - val_loss: 9.5653\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 782us/step - loss: 0.5421 - val_loss: 19.6344\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 779us/step - loss: 0.5153 - val_loss: 22.8742\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 825us/step - loss: 0.5157 - val_loss: 21.4868\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 781us/step - loss: 0.5130 - val_loss: 21.2682\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 816us/step - loss: 0.5103 - val_loss: 20.8302\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 775us/step - loss: 0.5121 - val_loss: 19.6148\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 839us/step - loss: 0.5107 - val_loss: 22.2889\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 800us/step - loss: 0.5070 - val_loss: 19.9837\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 823us/step - loss: 0.5089 - val_loss: 10.6759\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 761us/step - loss: 0.5084 - val_loss: 19.6798\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "121/121 [==============================] - 0s 507us/step - loss: 0.9637\n",
      "[CV] END learning_rate=0.01824796188192035, n_hidden=0, n_neurons=40; total time=   2.3s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 931us/step - loss: 1.2374 - val_loss: 471.0732\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 839us/step - loss: 1.2107 - val_loss: 154.7186\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 786us/step - loss: 1.5954 - val_loss: 1000.0496\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 825us/step - loss: 44.3432 - val_loss: 874.5897\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 793us/step - loss: 1.4489 - val_loss: 2978.5977\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 799us/step - loss: 10.4356 - val_loss: 1643.2432\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 816us/step - loss: 5.2959 - val_loss: 1723.9075\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 848us/step - loss: 46.9748 - val_loss: 1551.6956\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 920us/step - loss: 11.9606 - val_loss: 1468.7003\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 784us/step - loss: 1.5752 - val_loss: 265.6711\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 794us/step - loss: 16.6469 - val_loss: 158.5743\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 815us/step - loss: 0.6682 - val_loss: 7.4142\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 798us/step - loss: 0.7626 - val_loss: 854.9827\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 823us/step - loss: 10.1048 - val_loss: 512.7042\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 793us/step - loss: 2.3321 - val_loss: 1134.2444\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 783us/step - loss: 39.5939 - val_loss: 912.1135\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 788us/step - loss: 9.3228 - val_loss: 1176.4822\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 787us/step - loss: 4.0158 - val_loss: 527.8077\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 976us/step - loss: 26.2075 - val_loss: 329.9885\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 900us/step - loss: 3.9271 - val_loss: 383.2404\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 864us/step - loss: 4.4860 - val_loss: 591.6434\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 893us/step - loss: 4.8325 - val_loss: 418.3792\n",
      "121/121 [==============================] - 0s 807us/step - loss: 0.6383\n",
      "[CV] END learning_rate=0.01824796188192035, n_hidden=0, n_neurons=40; total time=   4.7s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.2424 - val_loss: 0.7111\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 905us/step - loss: 0.6124 - val_loss: 5.1980\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 882us/step - loss: 0.5454 - val_loss: 1.9375\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 949us/step - loss: 0.4753 - val_loss: 0.4102\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 934us/step - loss: 0.4249 - val_loss: 0.3987\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 940us/step - loss: 0.4058 - val_loss: 0.4098\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 937us/step - loss: 0.3925 - val_loss: 0.4092\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 918us/step - loss: 0.3820 - val_loss: 0.4154\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 902us/step - loss: 0.3750 - val_loss: 0.4097\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 962us/step - loss: 0.3691 - val_loss: 0.4076\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 891us/step - loss: 0.3635 - val_loss: 0.3912\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 978us/step - loss: 0.3578 - val_loss: 0.3834\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 926us/step - loss: 0.3525 - val_loss: 0.3886\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 968us/step - loss: 0.3498 - val_loss: 0.3856\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3450 - val_loss: 0.3759\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3421 - val_loss: 0.3764\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3379 - val_loss: 0.3687\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3349 - val_loss: 0.3681\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 979us/step - loss: 0.3311 - val_loss: 0.3569\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3282 - val_loss: 0.3545\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3254 - val_loss: 0.3635\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3232 - val_loss: 0.3654\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3204 - val_loss: 0.3890\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3193 - val_loss: 0.3272\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3145 - val_loss: 0.4465\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3143 - val_loss: 0.3532\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 893us/step - loss: 0.3144 - val_loss: 0.3697\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 954us/step - loss: 0.3133 - val_loss: 0.4050\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3098 - val_loss: 0.3978\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3071 - val_loss: 0.3152\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3053 - val_loss: 0.3345\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 983us/step - loss: 0.3042 - val_loss: 0.2984\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 969us/step - loss: 0.3027 - val_loss: 0.4702\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 973us/step - loss: 0.3007 - val_loss: 0.4623\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 937us/step - loss: 0.3004 - val_loss: 0.3602\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 937us/step - loss: 0.3003 - val_loss: 0.6571\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 954us/step - loss: 0.2997 - val_loss: 0.5137\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 986us/step - loss: 0.3041 - val_loss: 0.3919\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 963us/step - loss: 0.2985 - val_loss: 0.3063\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 945us/step - loss: 0.2968 - val_loss: 0.3774\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 941us/step - loss: 0.2957 - val_loss: 0.3041\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 940us/step - loss: 0.2938 - val_loss: 0.3209\n",
      "121/121 [==============================] - 0s 529us/step - loss: 0.3206\n",
      "[CV] END learning_rate=0.0045455096956331, n_hidden=3, n_neurons=30; total time=  10.4s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.1626 - val_loss: 1.4031\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 944us/step - loss: 0.5897 - val_loss: 0.7212\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 940us/step - loss: 0.5133 - val_loss: 0.5665\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 938us/step - loss: 0.4637 - val_loss: 0.4806\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 955us/step - loss: 0.4290 - val_loss: 0.4473\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 937us/step - loss: 0.4072 - val_loss: 0.4694\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 947us/step - loss: 0.3928 - val_loss: 0.5127\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 952us/step - loss: 0.3828 - val_loss: 0.5409\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 945us/step - loss: 0.3745 - val_loss: 0.6386\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3685 - val_loss: 0.6675\n",
      "Epoch 11/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 968us/step - loss: 0.3619 - val_loss: 0.7317\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 947us/step - loss: 0.3573 - val_loss: 0.7434\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 938us/step - loss: 0.3542 - val_loss: 0.8288\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 948us/step - loss: 0.3518 - val_loss: 0.9181\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 968us/step - loss: 0.3490 - val_loss: 0.9216\n",
      "121/121 [==============================] - 0s 589us/step - loss: 0.3631\n",
      "[CV] END learning_rate=0.0045455096956331, n_hidden=3, n_neurons=30; total time=   3.8s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.1925 - val_loss: 2.6833\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 912us/step - loss: 0.5754 - val_loss: 2.0872\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 935us/step - loss: 0.5045 - val_loss: 2.2561\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 945us/step - loss: 0.4737 - val_loss: 1.3509\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 930us/step - loss: 0.4313 - val_loss: 0.6347\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 934us/step - loss: 0.4109 - val_loss: 0.4183\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 925us/step - loss: 0.3992 - val_loss: 0.3604\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 937us/step - loss: 0.3909 - val_loss: 0.3602\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 933us/step - loss: 0.3836 - val_loss: 0.4063\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 960us/step - loss: 0.3816 - val_loss: 0.3534\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 964us/step - loss: 0.3746 - val_loss: 0.4468\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 957us/step - loss: 0.3717 - val_loss: 0.3467\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 952us/step - loss: 0.3662 - val_loss: 0.3456\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 953us/step - loss: 0.3635 - val_loss: 0.4147\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 941us/step - loss: 0.3622 - val_loss: 0.3382\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 943us/step - loss: 0.3574 - val_loss: 0.3754\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 930us/step - loss: 0.3563 - val_loss: 0.3443\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 935us/step - loss: 0.3534 - val_loss: 0.3495\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 928us/step - loss: 0.3516 - val_loss: 0.3649\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3487 - val_loss: 0.3550\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3482 - val_loss: 0.3293\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 978us/step - loss: 0.3457 - val_loss: 0.3280\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 934us/step - loss: 0.3438 - val_loss: 0.3433\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 977us/step - loss: 0.3423 - val_loss: 0.3686\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 945us/step - loss: 0.3423 - val_loss: 0.4526\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 918us/step - loss: 0.3403 - val_loss: 0.3798\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 939us/step - loss: 0.3389 - val_loss: 0.3264\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 941us/step - loss: 0.3374 - val_loss: 0.3250\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 950us/step - loss: 0.3371 - val_loss: 0.4458\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 936us/step - loss: 0.3375 - val_loss: 0.3203\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 987us/step - loss: 0.3329 - val_loss: 0.3397\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 973us/step - loss: 0.3320 - val_loss: 0.3475\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3311 - val_loss: 0.3211\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 991us/step - loss: 0.3291 - val_loss: 0.3566\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 963us/step - loss: 0.3311 - val_loss: 0.3516\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 953us/step - loss: 0.3280 - val_loss: 0.4465\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 984us/step - loss: 0.3295 - val_loss: 0.5253\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 956us/step - loss: 0.3364 - val_loss: 1.0497\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 946us/step - loss: 0.3355 - val_loss: 0.7913\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 964us/step - loss: 0.3315 - val_loss: 1.0090\n",
      "121/121 [==============================] - 0s 654us/step - loss: 0.3328\n",
      "[CV] END learning_rate=0.0045455096956331, n_hidden=3, n_neurons=30; total time=   9.7s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.1616 - val_loss: 7.7776\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 851us/step - loss: 0.9328 - val_loss: 3.4686\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 845us/step - loss: 0.7719 - val_loss: 1.1258\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 883us/step - loss: 0.6979 - val_loss: 0.7238\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 912us/step - loss: 0.6454 - val_loss: 0.6143\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 898us/step - loss: 0.6062 - val_loss: 0.5907\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 863us/step - loss: 0.5734 - val_loss: 0.5546\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 856us/step - loss: 0.5460 - val_loss: 0.5153\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 863us/step - loss: 0.5221 - val_loss: 0.5065\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 873us/step - loss: 0.5015 - val_loss: 0.5040\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 863us/step - loss: 0.4851 - val_loss: 0.4624\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 874us/step - loss: 0.4709 - val_loss: 0.4443\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 841us/step - loss: 0.4588 - val_loss: 0.4421\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 840us/step - loss: 0.4498 - val_loss: 0.4249\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 862us/step - loss: 0.4413 - val_loss: 0.4155\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 868us/step - loss: 0.4347 - val_loss: 0.4128\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4285 - val_loss: 0.4072\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 928us/step - loss: 0.4238 - val_loss: 0.3998\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 897us/step - loss: 0.4190 - val_loss: 0.3955\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 870us/step - loss: 0.4159 - val_loss: 0.3915\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 865us/step - loss: 0.4128 - val_loss: 0.3914\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 873us/step - loss: 0.4095 - val_loss: 0.3868\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 904us/step - loss: 0.4075 - val_loss: 0.3878\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 906us/step - loss: 0.4051 - val_loss: 0.3888\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 860us/step - loss: 0.4025 - val_loss: 0.3905\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 871us/step - loss: 0.4012 - val_loss: 0.3854\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 873us/step - loss: 0.3988 - val_loss: 0.4084\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 863us/step - loss: 0.3973 - val_loss: 0.3749\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 818us/step - loss: 0.3949 - val_loss: 0.3872\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 855us/step - loss: 0.3940 - val_loss: 0.3736\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 987us/step - loss: 0.3917 - val_loss: 0.3687\n",
      "Epoch 32/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 829us/step - loss: 0.3909 - val_loss: 0.3747\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 898us/step - loss: 0.3888 - val_loss: 0.3837\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 824us/step - loss: 0.3877 - val_loss: 0.3705\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 907us/step - loss: 0.3863 - val_loss: 0.3780\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 840us/step - loss: 0.3846 - val_loss: 0.4122\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 845us/step - loss: 0.3844 - val_loss: 0.4619\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 848us/step - loss: 0.3827 - val_loss: 0.4970\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 858us/step - loss: 0.3826 - val_loss: 0.4261\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 830us/step - loss: 0.3804 - val_loss: 0.4333\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 812us/step - loss: 0.3801 - val_loss: 0.3733\n",
      "121/121 [==============================] - 0s 532us/step - loss: 0.3926\n",
      "[CV] END learning_rate=0.0020587676114196545, n_hidden=1, n_neurons=49; total time=   9.0s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.5260 - val_loss: 0.8405\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 840us/step - loss: 0.6164 - val_loss: 0.6529\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 835us/step - loss: 0.5659 - val_loss: 0.8565\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 742us/step - loss: 0.5327 - val_loss: 1.1058\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 818us/step - loss: 0.5067 - val_loss: 1.3015\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 806us/step - loss: 0.4873 - val_loss: 1.3299\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 867us/step - loss: 0.4721 - val_loss: 1.3092\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 878us/step - loss: 0.4597 - val_loss: 1.2665\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 868us/step - loss: 0.4496 - val_loss: 1.0907\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 893us/step - loss: 0.4420 - val_loss: 0.9809\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 806us/step - loss: 0.4347 - val_loss: 0.8608\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 864us/step - loss: 0.4288 - val_loss: 0.7783\n",
      "121/121 [==============================] - 0s 536us/step - loss: 0.4558\n",
      "[CV] END learning_rate=0.0020587676114196545, n_hidden=1, n_neurons=49; total time=   2.7s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.6988 - val_loss: 1.4838\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 859us/step - loss: 0.6477 - val_loss: 0.7672\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 798us/step - loss: 0.5839 - val_loss: 0.5502\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 866us/step - loss: 0.5487 - val_loss: 0.5165\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 889us/step - loss: 0.5213 - val_loss: 0.6046\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 829us/step - loss: 0.4994 - val_loss: 0.4835\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 885us/step - loss: 0.4815 - val_loss: 0.4687\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 839us/step - loss: 0.4673 - val_loss: 0.4347\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 880us/step - loss: 0.4566 - val_loss: 0.5442\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 863us/step - loss: 0.4474 - val_loss: 0.4306\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 845us/step - loss: 0.4386 - val_loss: 0.4929\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 896us/step - loss: 0.4321 - val_loss: 0.4352\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 867us/step - loss: 0.4264 - val_loss: 0.4138\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 800us/step - loss: 0.4216 - val_loss: 0.5112\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 821us/step - loss: 0.4181 - val_loss: 0.3954\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 828us/step - loss: 0.4139 - val_loss: 0.5364\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 922us/step - loss: 0.4116 - val_loss: 0.3810\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 834us/step - loss: 0.4084 - val_loss: 0.4216\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 775us/step - loss: 0.4060 - val_loss: 0.4751\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 842us/step - loss: 0.4037 - val_loss: 0.4082\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 817us/step - loss: 0.4015 - val_loss: 0.4571\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 824us/step - loss: 0.4005 - val_loss: 0.3785\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 871us/step - loss: 0.3982 - val_loss: 0.4010\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 878us/step - loss: 0.3961 - val_loss: 0.4812\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 894us/step - loss: 0.3956 - val_loss: 0.3678\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 867us/step - loss: 0.3936 - val_loss: 0.3940\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 915us/step - loss: 0.3915 - val_loss: 0.5411\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 817us/step - loss: 0.3922 - val_loss: 0.3656\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 886us/step - loss: 0.3895 - val_loss: 0.7287\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 841us/step - loss: 0.3913 - val_loss: 0.3603\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 907us/step - loss: 0.3872 - val_loss: 0.4564\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 818us/step - loss: 0.3861 - val_loss: 0.4729\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 860us/step - loss: 0.3848 - val_loss: 0.4527\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 902us/step - loss: 0.3839 - val_loss: 0.4798\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 837us/step - loss: 0.3843 - val_loss: 0.3643\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 852us/step - loss: 0.3817 - val_loss: 0.4308\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 908us/step - loss: 0.3820 - val_loss: 0.3732\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 851us/step - loss: 0.3808 - val_loss: 0.7580\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 821us/step - loss: 0.3828 - val_loss: 0.4070\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 906us/step - loss: 0.3792 - val_loss: 0.7206\n",
      "121/121 [==============================] - 0s 528us/step - loss: 0.3753\n",
      "[CV] END learning_rate=0.0020587676114196545, n_hidden=1, n_neurons=49; total time=   8.6s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0311 - val_loss: 0.6675\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 897us/step - loss: 0.5325 - val_loss: 9.3039\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 963us/step - loss: 0.5235 - val_loss: 4.4621\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 922us/step - loss: 0.4445 - val_loss: 2.3111\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 957us/step - loss: 0.4100 - val_loss: 0.3863\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 955us/step - loss: 0.3766 - val_loss: 0.3671\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3658 - val_loss: 0.3732\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 941us/step - loss: 0.3578 - val_loss: 0.3796\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3526 - val_loss: 0.3763\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 963us/step - loss: 0.3487 - val_loss: 0.3673\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3451 - val_loss: 0.3561\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3400 - val_loss: 0.3591\n",
      "Epoch 13/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3364 - val_loss: 0.3452\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 945us/step - loss: 0.3343 - val_loss: 0.3532\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 921us/step - loss: 0.3311 - val_loss: 0.3439\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3289 - val_loss: 0.3487\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 924us/step - loss: 0.3260 - val_loss: 0.3392\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3244 - val_loss: 0.3444\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 976us/step - loss: 0.3211 - val_loss: 0.3444\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 926us/step - loss: 0.3192 - val_loss: 0.3315\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 971us/step - loss: 0.3172 - val_loss: 0.3395\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3157 - val_loss: 0.3456\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 965us/step - loss: 0.3129 - val_loss: 0.3333\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3120 - val_loss: 0.3201\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 968us/step - loss: 0.3082 - val_loss: 0.3344\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3063 - val_loss: 0.3234\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 939us/step - loss: 0.3063 - val_loss: 0.3238\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 944us/step - loss: 0.3049 - val_loss: 0.3325\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 992us/step - loss: 0.3022 - val_loss: 0.3282\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 973us/step - loss: 0.2996 - val_loss: 0.3068\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 972us/step - loss: 0.2988 - val_loss: 0.3007\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 964us/step - loss: 0.2977 - val_loss: 0.2969\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2951 - val_loss: 0.3107\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 991us/step - loss: 0.2937 - val_loss: 0.3123\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 990us/step - loss: 0.2921 - val_loss: 0.3014\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 986us/step - loss: 0.2909 - val_loss: 0.3396\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 987us/step - loss: 0.2900 - val_loss: 0.2877\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 972us/step - loss: 0.2883 - val_loss: 0.3276\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 970us/step - loss: 0.2881 - val_loss: 0.2982\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2864 - val_loss: 0.3264\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 965us/step - loss: 0.2844 - val_loss: 0.2912\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 968us/step - loss: 0.2834 - val_loss: 0.2932\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 972us/step - loss: 0.2831 - val_loss: 0.2854\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 964us/step - loss: 0.2809 - val_loss: 0.3058\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2801 - val_loss: 0.2813\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 965us/step - loss: 0.2786 - val_loss: 0.3131\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 992us/step - loss: 0.2777 - val_loss: 0.3015\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 929us/step - loss: 0.2777 - val_loss: 0.2914\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2755 - val_loss: 0.2752\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2752 - val_loss: 0.3020\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2736 - val_loss: 0.3079\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 975us/step - loss: 0.2717 - val_loss: 0.2974\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 972us/step - loss: 0.2719 - val_loss: 0.2829\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 966us/step - loss: 0.2697 - val_loss: 0.2843\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 973us/step - loss: 0.2690 - val_loss: 0.2982\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2688 - val_loss: 0.2759\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 980us/step - loss: 0.2662 - val_loss: 0.3059\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 976us/step - loss: 0.2670 - val_loss: 0.2799\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2662 - val_loss: 0.2782\n",
      "121/121 [==============================] - 0s 557us/step - loss: 0.3042\n",
      "[CV] END learning_rate=0.005803602934201024, n_hidden=3, n_neurons=74; total time=  14.4s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9962 - val_loss: 0.7476\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 991us/step - loss: 0.5353 - val_loss: 0.6829\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 965us/step - loss: 0.4454 - val_loss: 0.6652\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4091 - val_loss: 0.4463\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 936us/step - loss: 0.3884 - val_loss: 0.3703\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3744 - val_loss: 0.4874\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3667 - val_loss: 0.6903\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 954us/step - loss: 0.3589 - val_loss: 0.9398\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3518 - val_loss: 1.0865\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 974us/step - loss: 0.3482 - val_loss: 0.9943\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 971us/step - loss: 0.3427 - val_loss: 0.9885\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3389 - val_loss: 1.0791\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 985us/step - loss: 0.3358 - val_loss: 1.1445\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3382 - val_loss: 0.9923\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3317 - val_loss: 0.9813\n",
      "121/121 [==============================] - 0s 573us/step - loss: 0.3546\n",
      "[CV] END learning_rate=0.005803602934201024, n_hidden=3, n_neurons=74; total time=   3.9s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9503 - val_loss: 0.6962\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 984us/step - loss: 0.5272 - val_loss: 2.2302\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 978us/step - loss: 0.4763 - val_loss: 4.0457\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 983us/step - loss: 0.4806 - val_loss: 0.6351\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 937us/step - loss: 0.3998 - val_loss: 0.4404\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 923us/step - loss: 0.3835 - val_loss: 0.5154\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 994us/step - loss: 0.3726 - val_loss: 0.3510\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3630 - val_loss: 0.3719\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 971us/step - loss: 0.3547 - val_loss: 0.4193\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3523 - val_loss: 0.3326\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 974us/step - loss: 0.3451 - val_loss: 0.5269\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 969us/step - loss: 0.3430 - val_loss: 0.3263\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 971us/step - loss: 0.3375 - val_loss: 0.3456\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 969us/step - loss: 0.3337 - val_loss: 0.4935\n",
      "Epoch 15/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 966us/step - loss: 0.3343 - val_loss: 0.3846\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 984us/step - loss: 0.3303 - val_loss: 0.4701\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 955us/step - loss: 0.3281 - val_loss: 0.3291\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3229 - val_loss: 0.3619\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3210 - val_loss: 0.3829\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3176 - val_loss: 0.3322\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3160 - val_loss: 0.3323\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3148 - val_loss: 0.3353\n",
      "121/121 [==============================] - 0s 602us/step - loss: 0.3241\n",
      "[CV] END learning_rate=0.005803602934201024, n_hidden=3, n_neurons=74; total time=   5.7s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.9902 - val_loss: 1.8850\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 925us/step - loss: 0.5149 - val_loss: 2.0788\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 982us/step - loss: 0.4441 - val_loss: 0.5297\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 962us/step - loss: 0.3990 - val_loss: 0.4339\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3784 - val_loss: 0.3579\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 969us/step - loss: 0.3659 - val_loss: 0.4099\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3576 - val_loss: 0.3577\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 936us/step - loss: 0.3499 - val_loss: 0.4656\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 990us/step - loss: 0.3452 - val_loss: 0.3617\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3402 - val_loss: 0.4537\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3389 - val_loss: 0.3344\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3329 - val_loss: 0.4060\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 973us/step - loss: 0.3285 - val_loss: 0.3591\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3271 - val_loss: 0.3685\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 980us/step - loss: 0.3226 - val_loss: 0.3250\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3200 - val_loss: 0.4342\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 942us/step - loss: 0.3188 - val_loss: 0.3105\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3158 - val_loss: 0.5191\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 982us/step - loss: 0.3152 - val_loss: 0.3193\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3107 - val_loss: 0.5901\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3129 - val_loss: 0.3329\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3085 - val_loss: 0.7462\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3117 - val_loss: 0.4055\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3074 - val_loss: 0.4734\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3025 - val_loss: 0.3165\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2989 - val_loss: 0.3309\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2993 - val_loss: 0.3516\n",
      "121/121 [==============================] - 0s 606us/step - loss: 0.3368\n",
      "[CV] END learning_rate=0.0059640580092043885, n_hidden=3, n_neurons=80; total time=   7.1s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0137 - val_loss: 0.8554\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5067 - val_loss: 0.6755\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 986us/step - loss: 0.4199 - val_loss: 0.5173\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3889 - val_loss: 0.4596\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3721 - val_loss: 0.4052\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3613 - val_loss: 0.3379\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3547 - val_loss: 0.3537\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3494 - val_loss: 0.3972\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3431 - val_loss: 0.4889\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3393 - val_loss: 0.4304\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3340 - val_loss: 0.4930\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3309 - val_loss: 0.4943\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 985us/step - loss: 0.3280 - val_loss: 0.5745\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3271 - val_loss: 0.6098\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3250 - val_loss: 0.5812\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1000us/step - loss: 0.3203 - val_loss: 0.6459\n",
      "121/121 [==============================] - 0s 600us/step - loss: 0.3405\n",
      "[CV] END learning_rate=0.0059640580092043885, n_hidden=3, n_neurons=80; total time=   4.4s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9454 - val_loss: 0.5288\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4875 - val_loss: 0.4751\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4221 - val_loss: 0.7407\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4012 - val_loss: 2.2821\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3971 - val_loss: 3.3429\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3946 - val_loss: 1.4233\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3764 - val_loss: 0.4677\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3616 - val_loss: 0.3733\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3532 - val_loss: 0.4047\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3493 - val_loss: 0.3363\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3467 - val_loss: 0.4223\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3409 - val_loss: 0.3350\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3366 - val_loss: 0.3264\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3345 - val_loss: 0.4139\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3328 - val_loss: 0.3162\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 964us/step - loss: 0.3282 - val_loss: 0.3986\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3283 - val_loss: 0.3245\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 990us/step - loss: 0.3242 - val_loss: 0.4097\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3219 - val_loss: 0.3801\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3182 - val_loss: 0.3708\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3172 - val_loss: 0.3269\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3230 - val_loss: 0.3729\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3174 - val_loss: 0.4063\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3150 - val_loss: 0.3333\n",
      "Epoch 25/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3119 - val_loss: 0.3052\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3091 - val_loss: 0.3079\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3067 - val_loss: 0.3963\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3071 - val_loss: 0.3044\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3055 - val_loss: 0.4100\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3047 - val_loss: 0.3375\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3014 - val_loss: 0.3164\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2985 - val_loss: 0.4191\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2999 - val_loss: 0.3151\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2954 - val_loss: 0.4631\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3013 - val_loss: 0.3195\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2960 - val_loss: 0.3552\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2935 - val_loss: 0.3015\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2928 - val_loss: 0.3945\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2917 - val_loss: 0.2984\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2908 - val_loss: 0.3566\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2888 - val_loss: 0.3394\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2881 - val_loss: 0.3756\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2892 - val_loss: 0.2899\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2859 - val_loss: 0.3715\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2861 - val_loss: 0.3071\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2838 - val_loss: 0.3595\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2820 - val_loss: 0.2877\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2836 - val_loss: 0.2995\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2807 - val_loss: 0.4050\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2810 - val_loss: 0.2912\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2790 - val_loss: 0.3869\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2790 - val_loss: 0.2849\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2785 - val_loss: 0.3403\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2784 - val_loss: 0.2889\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2766 - val_loss: 0.3422\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2768 - val_loss: 0.2827\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2765 - val_loss: 0.3410\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2775 - val_loss: 0.2908\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2739 - val_loss: 0.3170\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2735 - val_loss: 0.3014\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2717 - val_loss: 0.3102\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2710 - val_loss: 0.3033\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2712 - val_loss: 0.2933\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2718 - val_loss: 0.3186\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2705 - val_loss: 0.2848\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2687 - val_loss: 0.3057\n",
      "121/121 [==============================] - 0s 653us/step - loss: 0.2919\n",
      "[CV] END learning_rate=0.0059640580092043885, n_hidden=3, n_neurons=80; total time=  17.7s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.1180 - val_loss: 1.3121\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 904us/step - loss: 0.5787 - val_loss: 0.9294\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4928 - val_loss: 1.4121\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 953us/step - loss: 0.4543 - val_loss: 5.5153\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4835 - val_loss: 17.3222\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 993us/step - loss: 0.6352 - val_loss: 1.0522\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 959us/step - loss: 0.4004 - val_loss: 0.5102\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 964us/step - loss: 0.3838 - val_loss: 0.4532\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3755 - val_loss: 0.4227\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3696 - val_loss: 0.4166\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 956us/step - loss: 0.3646 - val_loss: 0.3956\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3598 - val_loss: 0.3924\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1000us/step - loss: 0.3552 - val_loss: 0.4004\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 967us/step - loss: 0.3542 - val_loss: 0.4130\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3491 - val_loss: 0.3926\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 971us/step - loss: 0.3475 - val_loss: 0.3945\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3442 - val_loss: 0.3985\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 913us/step - loss: 0.3421 - val_loss: 0.3951\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 983us/step - loss: 0.3401 - val_loss: 0.3987\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3377 - val_loss: 0.3922\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 912us/step - loss: 0.3376 - val_loss: 0.4000\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 972us/step - loss: 0.3347 - val_loss: 0.3977\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 969us/step - loss: 0.3329 - val_loss: 0.3889\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 997us/step - loss: 0.3325 - val_loss: 0.3575\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3292 - val_loss: 0.3959\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 955us/step - loss: 0.3288 - val_loss: 0.3534\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 982us/step - loss: 0.3282 - val_loss: 0.3748\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 933us/step - loss: 0.3279 - val_loss: 0.3838\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 969us/step - loss: 0.3244 - val_loss: 0.3829\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 962us/step - loss: 0.3233 - val_loss: 0.3459\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 996us/step - loss: 0.3217 - val_loss: 0.3456\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 948us/step - loss: 0.3212 - val_loss: 0.3388\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 967us/step - loss: 0.3197 - val_loss: 0.3600\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 976us/step - loss: 0.3180 - val_loss: 0.3635\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 958us/step - loss: 0.3173 - val_loss: 0.3316\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 894us/step - loss: 0.3161 - val_loss: 0.3951\n",
      "Epoch 37/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 924us/step - loss: 0.3153 - val_loss: 0.3159\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 949us/step - loss: 0.3142 - val_loss: 0.3755\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 904us/step - loss: 0.3131 - val_loss: 0.3266\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 960us/step - loss: 0.3124 - val_loss: 0.3671\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 937us/step - loss: 0.3121 - val_loss: 0.3322\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 935us/step - loss: 0.3098 - val_loss: 0.3344\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 966us/step - loss: 0.3105 - val_loss: 0.3349\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 914us/step - loss: 0.3081 - val_loss: 0.3660\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 948us/step - loss: 0.3093 - val_loss: 0.3220\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 919us/step - loss: 0.3065 - val_loss: 0.3612\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 896us/step - loss: 0.3058 - val_loss: 0.3641\n",
      "121/121 [==============================] - 0s 657us/step - loss: 0.3353\n",
      "[CV] END learning_rate=0.004591455636549438, n_hidden=2, n_neurons=59; total time=  11.4s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9744 - val_loss: 2.9004\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 895us/step - loss: 0.5474 - val_loss: 0.5204\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 992us/step - loss: 0.4710 - val_loss: 0.4368\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 866us/step - loss: 0.4365 - val_loss: 0.4163\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 958us/step - loss: 0.4166 - val_loss: 0.3906\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 912us/step - loss: 0.4026 - val_loss: 0.4826\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 901us/step - loss: 0.3941 - val_loss: 0.6649\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 966us/step - loss: 0.3855 - val_loss: 0.7632\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 911us/step - loss: 0.3795 - val_loss: 0.9064\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 902us/step - loss: 0.3751 - val_loss: 0.7715\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 892us/step - loss: 0.3691 - val_loss: 0.8010\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 948us/step - loss: 0.3645 - val_loss: 0.7692\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 913us/step - loss: 0.3617 - val_loss: 0.8250\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 903us/step - loss: 0.3589 - val_loss: 0.8078\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 964us/step - loss: 0.3557 - val_loss: 0.7741\n",
      "121/121 [==============================] - 0s 550us/step - loss: 0.3702\n",
      "[CV] END learning_rate=0.004591455636549438, n_hidden=2, n_neurons=59; total time=   3.6s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3749 - val_loss: 8.4350\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 866us/step - loss: 0.6928 - val_loss: 2.3522\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 951us/step - loss: 0.5586 - val_loss: 0.4822\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 966us/step - loss: 0.4859 - val_loss: 0.4629\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 907us/step - loss: 0.4498 - val_loss: 0.4169\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 966us/step - loss: 0.4242 - val_loss: 0.4221\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 861us/step - loss: 0.4080 - val_loss: 0.3940\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 871us/step - loss: 0.3954 - val_loss: 0.3891\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 946us/step - loss: 0.3859 - val_loss: 0.3958\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 906us/step - loss: 0.3797 - val_loss: 0.3527\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 899us/step - loss: 0.3741 - val_loss: 0.4252\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 959us/step - loss: 0.3679 - val_loss: 0.3585\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 908us/step - loss: 0.3620 - val_loss: 0.3451\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3588 - val_loss: 0.3925\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 915us/step - loss: 0.3558 - val_loss: 0.3341\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 940us/step - loss: 0.3508 - val_loss: 0.3844\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 901us/step - loss: 0.3502 - val_loss: 0.3316\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 877us/step - loss: 0.3473 - val_loss: 0.3377\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 951us/step - loss: 0.3438 - val_loss: 0.3640\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 938us/step - loss: 0.3409 - val_loss: 0.3397\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 929us/step - loss: 0.3402 - val_loss: 0.3459\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 967us/step - loss: 0.3383 - val_loss: 0.3211\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 942us/step - loss: 0.3356 - val_loss: 0.3228\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 915us/step - loss: 0.3336 - val_loss: 0.3754\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 939us/step - loss: 0.3323 - val_loss: 0.3185\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 904us/step - loss: 0.3301 - val_loss: 0.3183\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 928us/step - loss: 0.3279 - val_loss: 0.3936\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 881us/step - loss: 0.3282 - val_loss: 0.3198\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 962us/step - loss: 0.3273 - val_loss: 0.4672\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 973us/step - loss: 0.3287 - val_loss: 0.3121\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 906us/step - loss: 0.3231 - val_loss: 0.3450\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 895us/step - loss: 0.3225 - val_loss: 0.3480\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 986us/step - loss: 0.3212 - val_loss: 0.3540\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 937us/step - loss: 0.3196 - val_loss: 0.3377\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 906us/step - loss: 0.3194 - val_loss: 0.3111\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 991us/step - loss: 0.3177 - val_loss: 0.3353\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 943us/step - loss: 0.3166 - val_loss: 0.3138\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 905us/step - loss: 0.3155 - val_loss: 0.4246\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 935us/step - loss: 0.3155 - val_loss: 0.3095\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 866us/step - loss: 0.3141 - val_loss: 0.3486\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 964us/step - loss: 0.3123 - val_loss: 0.3236\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 906us/step - loss: 0.3115 - val_loss: 0.3449\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 954us/step - loss: 0.3115 - val_loss: 0.3106\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 918us/step - loss: 0.3097 - val_loss: 0.3525\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 931us/step - loss: 0.3103 - val_loss: 0.3045\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 943us/step - loss: 0.3085 - val_loss: 0.4145\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 951us/step - loss: 0.3074 - val_loss: 0.3456\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 903us/step - loss: 0.3074 - val_loss: 0.3189\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 956us/step - loss: 0.3053 - val_loss: 0.3416\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 896us/step - loss: 0.3048 - val_loss: 0.3259\n",
      "Epoch 51/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 921us/step - loss: 0.3043 - val_loss: 0.3500\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 951us/step - loss: 0.3040 - val_loss: 0.3270\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 911us/step - loss: 0.3036 - val_loss: 0.3024\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 930us/step - loss: 0.3024 - val_loss: 0.3040\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 901us/step - loss: 0.3014 - val_loss: 0.3005\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 931us/step - loss: 0.3009 - val_loss: 0.3753\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 947us/step - loss: 0.3021 - val_loss: 0.3146\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 926us/step - loss: 0.3000 - val_loss: 0.3213\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 898us/step - loss: 0.2988 - val_loss: 0.3486\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 905us/step - loss: 0.2994 - val_loss: 0.3080\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 963us/step - loss: 0.2984 - val_loss: 0.3304\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 926us/step - loss: 0.2968 - val_loss: 0.3051\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 911us/step - loss: 0.2969 - val_loss: 0.2951\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 900us/step - loss: 0.2969 - val_loss: 0.3118\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 904us/step - loss: 0.2956 - val_loss: 0.2956\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 932us/step - loss: 0.2949 - val_loss: 0.3665\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 934us/step - loss: 0.2948 - val_loss: 0.3231\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 959us/step - loss: 0.2938 - val_loss: 0.6599\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 941us/step - loss: 0.2960 - val_loss: 0.5713\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 930us/step - loss: 0.2957 - val_loss: 0.5366\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 944us/step - loss: 0.2965 - val_loss: 0.3536\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 903us/step - loss: 0.2943 - val_loss: 0.3962\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 915us/step - loss: 0.2940 - val_loss: 0.5096\n",
      "121/121 [==============================] - 0s 541us/step - loss: 0.3069\n",
      "[CV] END learning_rate=0.004591455636549438, n_hidden=2, n_neurons=59; total time=  16.8s\n",
      "Epoch 1/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.8469 - val_loss: 2.7917\n",
      "Epoch 2/100\n",
      "363/363 [==============================] - 0s 884us/step - loss: 0.4862 - val_loss: 2.0540\n",
      "Epoch 3/100\n",
      "363/363 [==============================] - 0s 867us/step - loss: 0.4255 - val_loss: 0.3861\n",
      "Epoch 4/100\n",
      "363/363 [==============================] - 0s 879us/step - loss: 0.3824 - val_loss: 0.3836\n",
      "Epoch 5/100\n",
      "363/363 [==============================] - 0s 882us/step - loss: 0.3685 - val_loss: 0.3693\n",
      "Epoch 6/100\n",
      "363/363 [==============================] - 0s 861us/step - loss: 0.3587 - val_loss: 0.3783\n",
      "Epoch 7/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3568 - val_loss: 0.3603\n",
      "Epoch 8/100\n",
      "363/363 [==============================] - 0s 921us/step - loss: 0.3455 - val_loss: 0.3403\n",
      "Epoch 9/100\n",
      "363/363 [==============================] - 0s 877us/step - loss: 0.3394 - val_loss: 0.3546\n",
      "Epoch 10/100\n",
      "363/363 [==============================] - 0s 887us/step - loss: 0.3350 - val_loss: 0.4303\n",
      "Epoch 11/100\n",
      "363/363 [==============================] - 0s 919us/step - loss: 0.3332 - val_loss: 0.3330\n",
      "Epoch 12/100\n",
      "363/363 [==============================] - 0s 899us/step - loss: 0.3308 - val_loss: 0.4092\n",
      "Epoch 13/100\n",
      "363/363 [==============================] - 0s 897us/step - loss: 0.3255 - val_loss: 0.3124\n",
      "Epoch 14/100\n",
      "363/363 [==============================] - 0s 869us/step - loss: 0.3213 - val_loss: 0.3112\n",
      "Epoch 15/100\n",
      "363/363 [==============================] - 0s 918us/step - loss: 0.3192 - val_loss: 0.3215\n",
      "Epoch 16/100\n",
      "363/363 [==============================] - 0s 924us/step - loss: 0.3161 - val_loss: 0.3081\n",
      "Epoch 17/100\n",
      "363/363 [==============================] - 0s 924us/step - loss: 0.3134 - val_loss: 0.4582\n",
      "Epoch 18/100\n",
      "363/363 [==============================] - 0s 924us/step - loss: 0.3110 - val_loss: 0.3097\n",
      "Epoch 19/100\n",
      "363/363 [==============================] - 0s 928us/step - loss: 0.3094 - val_loss: 0.3177\n",
      "Epoch 20/100\n",
      "363/363 [==============================] - 0s 902us/step - loss: 0.3073 - val_loss: 0.3938\n",
      "Epoch 21/100\n",
      "363/363 [==============================] - 0s 886us/step - loss: 0.3042 - val_loss: 0.3232\n",
      "Epoch 22/100\n",
      "363/363 [==============================] - 0s 936us/step - loss: 0.3014 - val_loss: 0.5828\n",
      "Epoch 23/100\n",
      "363/363 [==============================] - 0s 906us/step - loss: 0.3021 - val_loss: 0.7226\n",
      "Epoch 24/100\n",
      "363/363 [==============================] - 0s 960us/step - loss: 0.3019 - val_loss: 0.5059\n",
      "Epoch 25/100\n",
      "363/363 [==============================] - 0s 919us/step - loss: 0.2985 - val_loss: 0.2992\n",
      "Epoch 26/100\n",
      "363/363 [==============================] - 0s 964us/step - loss: 0.2951 - val_loss: 0.3627\n",
      "Epoch 27/100\n",
      "363/363 [==============================] - 0s 921us/step - loss: 0.2933 - val_loss: 0.3712\n",
      "Epoch 28/100\n",
      "363/363 [==============================] - 0s 923us/step - loss: 0.2930 - val_loss: 0.4736\n",
      "Epoch 29/100\n",
      "363/363 [==============================] - 0s 919us/step - loss: 0.2905 - val_loss: 0.2886\n",
      "Epoch 30/100\n",
      "363/363 [==============================] - 0s 897us/step - loss: 0.2892 - val_loss: 0.3605\n",
      "Epoch 31/100\n",
      "363/363 [==============================] - 0s 901us/step - loss: 0.2905 - val_loss: 0.2891\n",
      "Epoch 32/100\n",
      "363/363 [==============================] - 0s 897us/step - loss: 0.2855 - val_loss: 0.3281\n",
      "Epoch 33/100\n",
      "363/363 [==============================] - 0s 940us/step - loss: 0.2848 - val_loss: 0.2804\n",
      "Epoch 34/100\n",
      "363/363 [==============================] - 0s 947us/step - loss: 0.2830 - val_loss: 0.3077\n",
      "Epoch 35/100\n",
      "363/363 [==============================] - 0s 966us/step - loss: 0.2816 - val_loss: 0.3366\n",
      "Epoch 36/100\n",
      "363/363 [==============================] - 0s 911us/step - loss: 0.2814 - val_loss: 0.2937\n",
      "Epoch 37/100\n",
      "363/363 [==============================] - 0s 927us/step - loss: 0.2793 - val_loss: 0.3988\n",
      "Epoch 38/100\n",
      "363/363 [==============================] - 0s 907us/step - loss: 0.2773 - val_loss: 0.2798\n",
      "Epoch 39/100\n",
      "363/363 [==============================] - 0s 965us/step - loss: 0.2779 - val_loss: 0.3207\n",
      "Epoch 40/100\n",
      "363/363 [==============================] - 0s 900us/step - loss: 0.2773 - val_loss: 0.3043\n",
      "Epoch 41/100\n",
      "363/363 [==============================] - 0s 922us/step - loss: 0.2769 - val_loss: 0.3945\n",
      "Epoch 42/100\n",
      "363/363 [==============================] - 0s 899us/step - loss: 0.2778 - val_loss: 0.2837\n",
      "Epoch 43/100\n",
      "363/363 [==============================] - 0s 939us/step - loss: 0.2721 - val_loss: 0.3611\n",
      "Epoch 44/100\n",
      "363/363 [==============================] - 0s 918us/step - loss: 0.2730 - val_loss: 0.2925\n",
      "Epoch 45/100\n",
      "363/363 [==============================] - 0s 958us/step - loss: 0.2709 - val_loss: 0.2760\n",
      "Epoch 46/100\n",
      "363/363 [==============================] - 0s 926us/step - loss: 0.2709 - val_loss: 0.2948\n",
      "Epoch 47/100\n",
      "363/363 [==============================] - 0s 919us/step - loss: 0.2717 - val_loss: 0.3430\n",
      "Epoch 48/100\n",
      "363/363 [==============================] - 0s 923us/step - loss: 0.2704 - val_loss: 0.3093\n",
      "Epoch 49/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2687 - val_loss: 0.2928\n",
      "Epoch 50/100\n",
      "363/363 [==============================] - 0s 965us/step - loss: 0.2675 - val_loss: 0.3017\n",
      "Epoch 51/100\n",
      "363/363 [==============================] - 0s 967us/step - loss: 0.2663 - val_loss: 0.2895\n",
      "Epoch 52/100\n",
      "363/363 [==============================] - 0s 966us/step - loss: 0.2652 - val_loss: 0.3075\n",
      "Epoch 53/100\n",
      "363/363 [==============================] - 0s 968us/step - loss: 0.2656 - val_loss: 0.4633\n",
      "Epoch 54/100\n",
      "363/363 [==============================] - 0s 925us/step - loss: 0.2653 - val_loss: 0.4410\n",
      "Epoch 55/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "363/363 [==============================] - 0s 924us/step - loss: 0.2653 - val_loss: 0.4681\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3,\n",
       "                   estimator=<keras.wrappers.scikit_learn.KerasRegressor object at 0x000001CAD1E36E20>,\n",
       "                   param_distributions={'learning_rate': [0.001683454924600351,\n",
       "                                                          0.02390836445593178,\n",
       "                                                          0.008731907739399206,\n",
       "                                                          0.004725396149933917,\n",
       "                                                          0.0006154014789262348,\n",
       "                                                          0.0006153331256530192,\n",
       "                                                          0.0003920021771415983,\n",
       "                                                          0.01619845322936229,\n",
       "                                                          0.004779156784872302,\n",
       "                                                          0.007821074275112...\n",
       "                                                          0.005021425736625637,\n",
       "                                                          0.0005703073595961105,\n",
       "                                                          0.001151888789941251,\n",
       "                                                          0.001621231156394198,\n",
       "                                                          0.0024505367684280487,\n",
       "                                                          0.011155092541719619,\n",
       "                                                          0.0007524347058135697,\n",
       "                                                          0.0032032448128444043,\n",
       "                                                          0.004591455636549438,\n",
       "                                                          0.0003715541189658278, ...],\n",
       "                                        'n_hidden': [0, 1, 2, 3],\n",
       "                                        'n_neurons': [1, 2, 3, 4, 5, 6, 7, 8, 9,\n",
       "                                                      10, 11, 12, 13, 14, 15,\n",
       "                                                      16, 17, 18, 19, 20, 21,\n",
       "                                                      22, 23, 24, 25, 26, 27,\n",
       "                                                      28, 29, 30, ...]},\n",
       "                   verbose=2)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import reciprocal\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "param_distribs = {\n",
    "    \"n_hidden\": [0, 1, 2, 3],\n",
    "    \"n_neurons\": np.arange(1, 100).tolist(),\n",
    "    \"learning_rate\": reciprocal(3e-4, 3e-2).rvs(1000).tolist(),\n",
    "}\n",
    "\n",
    "rnd_search_cv = RandomizedSearchCV(keras_reg, param_distribs, n_iter=10, cv=3, verbose=2)\n",
    "rnd_search_cv.fit(X_train, y_train, epochs=100,\n",
    "                  validation_data=(X_valid, y_valid),\n",
    "                  callbacks=[keras.callbacks.EarlyStopping(patience=10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9f9dde7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_neurons': 80, 'n_hidden': 3, 'learning_rate': 0.0059640580092043885}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "25dc0c27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.3230697313944499"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9599301e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.wrappers.scikit_learn.KerasRegressor at 0x1cad51e5970>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "582fad8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 498us/step - loss: 0.2871\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-0.2871443033218384"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5c913f4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x1cad4162d60>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = rnd_search_cv.best_estimator_.model\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b2bc24d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 464us/step - loss: 0.2871\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.2871443033218384"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e09e1e1e",
   "metadata": {},
   "source": [
    "### Chapter 11 심층 신경망 훈련하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ecf5dc69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.layers.core.dense.Dense at 0x1cad52e0b20>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.layers.Dense(10, activation=\"relu\", kernel_initializer=\"he_normal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "06a606e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.layers.core.dense.Dense at 0x1cad4149340>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init = keras.initializers.VarianceScaling(scale=2., mode='fan_avg',\n",
    "                                          distribution='uniform')\n",
    "keras.layers.Dense(10, activation=\"relu\", kernel_initializer=init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "787df938",
   "metadata": {},
   "outputs": [],
   "source": [
    "def leaky_relu(z, alpha=0.01):\n",
    "    return np.maximum(alpha*z, z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "55d49c5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 266,
       "width": 361
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "z = np.linspace(-5, 5, 200)\n",
    "plt.plot(z, leaky_relu(z, 0.05), \"b-\", linewidth=2)\n",
    "plt.plot([-5, 5], [0, 0], 'k-')\n",
    "plt.plot([0, 0], [-0.5, 4.2], 'k-')\n",
    "plt.grid(True)\n",
    "props = dict(facecolor='black', shrink=0.1)\n",
    "plt.annotate('Leak', xytext=(-3.5, 0.5), xy=(-5, -0.2), arrowprops=props, fontsize=14, ha=\"center\")\n",
    "plt.title(\"Leaky ReLU activation function\", fontsize=14)\n",
    "plt.axis([-5, 5, -0.5, 4.2])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a8d601a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train_full, y_train_full), (X_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
    "X_train_full = X_train_full / 255.0\n",
    "X_test = X_test / 255.0\n",
    "X_valid, X_train = X_train_full[:5000], X_train_full[5000:]\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5ce57d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, kernel_initializer=\"he_normal\"),\n",
    "    keras.layers.LeakyReLU(),\n",
    "    keras.layers.Dense(100, kernel_initializer=\"he_normal\"),\n",
    "    keras.layers.LeakyReLU(),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "90db2595",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=keras.optimizers.SGD(learning_rate=1e-3),\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c05a3925",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 1.2819 - accuracy: 0.6229 - val_loss: 0.8886 - val_accuracy: 0.7160\n",
      "Epoch 2/10\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.7955 - accuracy: 0.7362 - val_loss: 0.7130 - val_accuracy: 0.7658\n",
      "Epoch 3/10\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.6816 - accuracy: 0.7722 - val_loss: 0.6427 - val_accuracy: 0.7898\n",
      "Epoch 4/10\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.6217 - accuracy: 0.7943 - val_loss: 0.5900 - val_accuracy: 0.8066\n",
      "Epoch 5/10\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.5832 - accuracy: 0.8074 - val_loss: 0.5582 - val_accuracy: 0.8202\n",
      "Epoch 6/10\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.5553 - accuracy: 0.8157 - val_loss: 0.5350 - val_accuracy: 0.8238\n",
      "Epoch 7/10\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.5338 - accuracy: 0.8225 - val_loss: 0.5157 - val_accuracy: 0.8304\n",
      "Epoch 8/10\n",
      "1719/1719 [==============================] - 3s 1ms/step - loss: 0.5172 - accuracy: 0.8273 - val_loss: 0.5079 - val_accuracy: 0.8286\n",
      "Epoch 9/10\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.5040 - accuracy: 0.8290 - val_loss: 0.4895 - val_accuracy: 0.8386\n",
      "Epoch 10/10\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.4924 - accuracy: 0.8321 - val_loss: 0.4817 - val_accuracy: 0.8396\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=10,\n",
    "                    validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b5671f4",
   "metadata": {},
   "source": [
    "#### 케라스로 배치 정규화 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7265cf65",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(300, activation=\"relu\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(100, activation=\"relu\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "166ead5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_36\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_1 (Flatten)         (None, 784)               0         \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 784)              3136      \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dense_102 (Dense)           (None, 300)               235500    \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 300)              1200      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_103 (Dense)           (None, 100)               30100     \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 100)              400       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_104 (Dense)           (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 271,346\n",
      "Trainable params: 268,978\n",
      "Non-trainable params: 2,368\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8985855f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('batch_normalization/gamma:0', True),\n",
       " ('batch_normalization/beta:0', True),\n",
       " ('batch_normalization/moving_mean:0', False),\n",
       " ('batch_normalization/moving_variance:0', False)]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bn1 = model.layers[1]\n",
    "[(var.name, var.trainable) for var in bn1.variables]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "746edf3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(300, use_bias=False),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Activation(\"relu\"),\n",
    "    keras.layers.Dense(100, use_bias=False),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Activation(\"relu\"),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7f9ad805",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=keras.optimizers.SGD(learning_rate=1e-3),\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "92869b1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 1.0346 - accuracy: 0.6739 - val_loss: 0.6680 - val_accuracy: 0.7888\n",
      "Epoch 2/10\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.6757 - accuracy: 0.7819 - val_loss: 0.5537 - val_accuracy: 0.8210\n",
      "Epoch 3/10\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.5961 - accuracy: 0.8021 - val_loss: 0.4996 - val_accuracy: 0.8350\n",
      "Epoch 4/10\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.5456 - accuracy: 0.8176 - val_loss: 0.4655 - val_accuracy: 0.8458\n",
      "Epoch 5/10\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.5140 - accuracy: 0.8247 - val_loss: 0.4420 - val_accuracy: 0.8512\n",
      "Epoch 6/10\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.4915 - accuracy: 0.8310 - val_loss: 0.4237 - val_accuracy: 0.8538\n",
      "Epoch 7/10\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.4741 - accuracy: 0.8377 - val_loss: 0.4103 - val_accuracy: 0.8580\n",
      "Epoch 8/10\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.4603 - accuracy: 0.8408 - val_loss: 0.3994 - val_accuracy: 0.8622\n",
      "Epoch 9/10\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.4465 - accuracy: 0.8458 - val_loss: 0.3911 - val_accuracy: 0.8638\n",
      "Epoch 10/10\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.4338 - accuracy: 0.8498 - val_loss: 0.3828 - val_accuracy: 0.8674\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=10,\n",
    "                    validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76659735",
   "metadata": {},
   "source": [
    "#### 그레이디언트 클리핑"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a6f9beb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.SGD(clipvalue=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e83fb7a",
   "metadata": {},
   "source": [
    "#### 사전 훈련된 층 재사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c3636a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(X, y):\n",
    "    y_5_or_6 = (y == 5) | (y == 6) # sandals or shirts\n",
    "    y_A = y[~y_5_or_6]\n",
    "    y_A[y_A > 6] -= 2 # class indices 7, 8, 9 should be moved to 5, 6, 7\n",
    "    y_B = (y[y_5_or_6] == 6).astype(np.float32) # binary classification task: is it a shirt (class 6)?\n",
    "    return ((X[~y_5_or_6], y_A),\n",
    "            (X[y_5_or_6], y_B))\n",
    "\n",
    "(X_train_A, y_train_A), (X_train_B, y_train_B) = split_dataset(X_train, y_train)\n",
    "(X_valid_A, y_valid_A), (X_valid_B, y_valid_B) = split_dataset(X_valid, y_valid)\n",
    "(X_test_A, y_test_A), (X_test_B, y_test_B) = split_dataset(X_test, y_test)\n",
    "X_train_B = X_train_B[:200]\n",
    "y_train_B = y_train_B[:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "63e3dc7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_A = keras.models.Sequential()\n",
    "model_A.add(keras.layers.Flatten(input_shape=[28, 28]))\n",
    "for n_hidden in (300, 100, 50, 50, 50):\n",
    "    model_A.add(keras.layers.Dense(n_hidden, activation=\"selu\"))\n",
    "model_A.add(keras.layers.Dense(8, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e9dd111c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_A.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "                optimizer=keras.optimizers.SGD(learning_rate=1e-3),\n",
    "                metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "296028be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1375/1375 [==============================] - 2s 1ms/step - loss: 0.5822 - accuracy: 0.8129 - val_loss: 0.3812 - val_accuracy: 0.8660\n",
      "Epoch 2/20\n",
      "1375/1375 [==============================] - 2s 1ms/step - loss: 0.3565 - accuracy: 0.8775 - val_loss: 0.3212 - val_accuracy: 0.8891\n",
      "Epoch 3/20\n",
      "1375/1375 [==============================] - 2s 1ms/step - loss: 0.3184 - accuracy: 0.8897 - val_loss: 0.2934 - val_accuracy: 0.9001\n",
      "Epoch 4/20\n",
      "1375/1375 [==============================] - 2s 1ms/step - loss: 0.2975 - accuracy: 0.8975 - val_loss: 0.2790 - val_accuracy: 0.9043\n",
      "Epoch 5/20\n",
      "1375/1375 [==============================] - 2s 1ms/step - loss: 0.2837 - accuracy: 0.9017 - val_loss: 0.2680 - val_accuracy: 0.9078\n",
      "Epoch 6/20\n",
      "1375/1375 [==============================] - 2s 1ms/step - loss: 0.2731 - accuracy: 0.9058 - val_loss: 0.2616 - val_accuracy: 0.9108\n",
      "Epoch 7/20\n",
      "1375/1375 [==============================] - 2s 2ms/step - loss: 0.2645 - accuracy: 0.9094 - val_loss: 0.2610 - val_accuracy: 0.9138\n",
      "Epoch 8/20\n",
      "1375/1375 [==============================] - 2s 2ms/step - loss: 0.2578 - accuracy: 0.9122 - val_loss: 0.2523 - val_accuracy: 0.9153\n",
      "Epoch 9/20\n",
      "1375/1375 [==============================] - 2s 2ms/step - loss: 0.2523 - accuracy: 0.9133 - val_loss: 0.2491 - val_accuracy: 0.9158\n",
      "Epoch 10/20\n",
      "1375/1375 [==============================] - 2s 2ms/step - loss: 0.2472 - accuracy: 0.9158 - val_loss: 0.2464 - val_accuracy: 0.9155\n",
      "Epoch 11/20\n",
      "1375/1375 [==============================] - 2s 1ms/step - loss: 0.2425 - accuracy: 0.9170 - val_loss: 0.2417 - val_accuracy: 0.9190\n",
      "Epoch 12/20\n",
      "1375/1375 [==============================] - 2s 1ms/step - loss: 0.2384 - accuracy: 0.9181 - val_loss: 0.2408 - val_accuracy: 0.9173\n",
      "Epoch 13/20\n",
      "1375/1375 [==============================] - 2s 1ms/step - loss: 0.2351 - accuracy: 0.9188 - val_loss: 0.2377 - val_accuracy: 0.9178\n",
      "Epoch 14/20\n",
      "1375/1375 [==============================] - 2s 1ms/step - loss: 0.2316 - accuracy: 0.9209 - val_loss: 0.2350 - val_accuracy: 0.9183\n",
      "Epoch 15/20\n",
      "1375/1375 [==============================] - 2s 2ms/step - loss: 0.2286 - accuracy: 0.9215 - val_loss: 0.2392 - val_accuracy: 0.9170\n",
      "Epoch 16/20\n",
      "1375/1375 [==============================] - 2s 2ms/step - loss: 0.2253 - accuracy: 0.9232 - val_loss: 0.2350 - val_accuracy: 0.9178\n",
      "Epoch 17/20\n",
      "1375/1375 [==============================] - 2s 2ms/step - loss: 0.2229 - accuracy: 0.9242 - val_loss: 0.2353 - val_accuracy: 0.9150\n",
      "Epoch 18/20\n",
      "1375/1375 [==============================] - 2s 2ms/step - loss: 0.2199 - accuracy: 0.9242 - val_loss: 0.2384 - val_accuracy: 0.9145\n",
      "Epoch 19/20\n",
      "1375/1375 [==============================] - 2s 2ms/step - loss: 0.2177 - accuracy: 0.9257 - val_loss: 0.2278 - val_accuracy: 0.9193\n",
      "Epoch 20/20\n",
      "1375/1375 [==============================] - 2s 2ms/step - loss: 0.2150 - accuracy: 0.9273 - val_loss: 0.2280 - val_accuracy: 0.9188\n"
     ]
    }
   ],
   "source": [
    "history = model_A.fit(X_train_A, y_train_A, epochs=20,\n",
    "                    validation_data=(X_valid_A, y_valid_A))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a2be7083",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_A.save(\"my_model_A.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fb26e879",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_B = keras.models.Sequential()\n",
    "model_B.add(keras.layers.Flatten(input_shape=[28, 28]))\n",
    "for n_hidden in (300, 100, 50, 50, 50):\n",
    "    model_B.add(keras.layers.Dense(n_hidden, activation=\"selu\"))\n",
    "model_B.add(keras.layers.Dense(1, activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b41520bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_B.compile(loss=\"binary_crossentropy\",\n",
    "                optimizer=keras.optimizers.SGD(learning_rate=1e-3),\n",
    "                metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8b1aac4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.8671 - accuracy: 0.4650 - val_loss: 0.6258 - val_accuracy: 0.6359\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.5619 - accuracy: 0.7650 - val_loss: 0.4965 - val_accuracy: 0.8185\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4569 - accuracy: 0.8850 - val_loss: 0.4278 - val_accuracy: 0.8763\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3953 - accuracy: 0.9150 - val_loss: 0.3786 - val_accuracy: 0.9067\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.3499 - accuracy: 0.9350 - val_loss: 0.3397 - val_accuracy: 0.9351\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.3128 - accuracy: 0.9450 - val_loss: 0.3081 - val_accuracy: 0.9452\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.2834 - accuracy: 0.9650 - val_loss: 0.2837 - val_accuracy: 0.9554\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.2592 - accuracy: 0.9750 - val_loss: 0.2616 - val_accuracy: 0.9625\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.2378 - accuracy: 0.9850 - val_loss: 0.2427 - val_accuracy: 0.9665\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.2192 - accuracy: 0.9850 - val_loss: 0.2264 - val_accuracy: 0.9716\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.2032 - accuracy: 0.9850 - val_loss: 0.2116 - val_accuracy: 0.9736\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.1888 - accuracy: 0.9850 - val_loss: 0.1992 - val_accuracy: 0.9736\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.1766 - accuracy: 0.9850 - val_loss: 0.1886 - val_accuracy: 0.9736\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.1662 - accuracy: 0.9900 - val_loss: 0.1787 - val_accuracy: 0.9757\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.1563 - accuracy: 0.9900 - val_loss: 0.1699 - val_accuracy: 0.9767\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.1474 - accuracy: 0.9900 - val_loss: 0.1621 - val_accuracy: 0.9787\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.1397 - accuracy: 0.9900 - val_loss: 0.1550 - val_accuracy: 0.9787\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.1329 - accuracy: 0.9900 - val_loss: 0.1486 - val_accuracy: 0.9797\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.1261 - accuracy: 0.9900 - val_loss: 0.1427 - val_accuracy: 0.9797\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.1203 - accuracy: 0.9900 - val_loss: 0.1373 - val_accuracy: 0.9797\n"
     ]
    }
   ],
   "source": [
    "history = model_B.fit(X_train_B, y_train_B, epochs=20,\n",
    "                      validation_data=(X_valid_B, y_valid_B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "af07bdaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_39\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_4 (Flatten)         (None, 784)               0         \n",
      "                                                                 \n",
      " dense_114 (Dense)           (None, 300)               235500    \n",
      "                                                                 \n",
      " dense_115 (Dense)           (None, 100)               30100     \n",
      "                                                                 \n",
      " dense_116 (Dense)           (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_117 (Dense)           (None, 50)                2550      \n",
      "                                                                 \n",
      " dense_118 (Dense)           (None, 50)                2550      \n",
      "                                                                 \n",
      " dense_119 (Dense)           (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 275,801\n",
      "Trainable params: 275,801\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_B.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ba634ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_A = keras.models.load_model(\"my_model_A.h5\")\n",
    "model_B_on_A = keras.models.Sequential(model_A.layers[:-1])\n",
    "model_B_on_A.add(keras.layers.Dense(1, activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "92c158bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_A_clone = keras.models.clone_model(model_A)\n",
    "model_A_clone.set_weights(model_A.get_weights())\n",
    "model_B_on_A = keras.models.Sequential(model_A_clone.layers[:-1])\n",
    "model_B_on_A.add(keras.layers.Dense(1, activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "469401dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model_B_on_A.layers[:-1]:\n",
    "    layer.trainable = False\n",
    "\n",
    "model_B_on_A.compile(loss=\"binary_crossentropy\",\n",
    "                     optimizer=keras.optimizers.SGD(learning_rate=1e-3),\n",
    "                     metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "006e7334",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "7/7 [==============================] - 0s 26ms/step - loss: 1.5563 - accuracy: 0.0500 - val_loss: 1.4224 - val_accuracy: 0.0710\n",
      "Epoch 2/4\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.4006 - accuracy: 0.0850 - val_loss: 1.2843 - val_accuracy: 0.1045\n",
      "Epoch 3/4\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.2610 - accuracy: 0.1150 - val_loss: 1.1617 - val_accuracy: 0.1481\n",
      "Epoch 4/4\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.1372 - accuracy: 0.1700 - val_loss: 1.0495 - val_accuracy: 0.1988\n",
      "Epoch 1/16\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 0.8631 - accuracy: 0.3600 - val_loss: 0.6130 - val_accuracy: 0.6988\n",
      "Epoch 2/16\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.5077 - accuracy: 0.7950 - val_loss: 0.4118 - val_accuracy: 0.9077\n",
      "Epoch 3/16\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.3429 - accuracy: 0.9500 - val_loss: 0.3062 - val_accuracy: 0.9594\n",
      "Epoch 4/16\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.2554 - accuracy: 0.9800 - val_loss: 0.2422 - val_accuracy: 0.9736\n",
      "Epoch 5/16\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.2016 - accuracy: 0.9850 - val_loss: 0.2016 - val_accuracy: 0.9858\n",
      "Epoch 6/16\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.1665 - accuracy: 0.9900 - val_loss: 0.1734 - val_accuracy: 0.9888\n",
      "Epoch 7/16\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.1419 - accuracy: 0.9950 - val_loss: 0.1528 - val_accuracy: 0.9888\n",
      "Epoch 8/16\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.1236 - accuracy: 0.9950 - val_loss: 0.1371 - val_accuracy: 0.9888\n",
      "Epoch 9/16\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.1095 - accuracy: 0.9950 - val_loss: 0.1240 - val_accuracy: 0.9888\n",
      "Epoch 10/16\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0980 - accuracy: 0.9950 - val_loss: 0.1143 - val_accuracy: 0.9888\n",
      "Epoch 11/16\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0892 - accuracy: 0.9950 - val_loss: 0.1061 - val_accuracy: 0.9888\n",
      "Epoch 12/16\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.0816 - accuracy: 0.9950 - val_loss: 0.0991 - val_accuracy: 0.9888\n",
      "Epoch 13/16\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.0753 - accuracy: 0.9950 - val_loss: 0.0932 - val_accuracy: 0.9899\n",
      "Epoch 14/16\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0699 - accuracy: 0.9950 - val_loss: 0.0880 - val_accuracy: 0.9899\n",
      "Epoch 15/16\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.0649 - accuracy: 0.9950 - val_loss: 0.0837 - val_accuracy: 0.9899\n",
      "Epoch 16/16\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.0610 - accuracy: 0.9950 - val_loss: 0.0798 - val_accuracy: 0.9899\n"
     ]
    }
   ],
   "source": [
    "history = model_B_on_A.fit(X_train_B, y_train_B, epochs=4,\n",
    "                           validation_data=(X_valid_B, y_valid_B))\n",
    "\n",
    "for layer in model_B_on_A.layers[:-1]:\n",
    "    layer.trainable = True\n",
    "\n",
    "model_B_on_A.compile(loss=\"binary_crossentropy\",\n",
    "                     optimizer=keras.optimizers.SGD(learning_rate=1e-3),\n",
    "                     metrics=[\"accuracy\"])\n",
    "history = model_B_on_A.fit(X_train_B, y_train_B, epochs=16,\n",
    "                           validation_data=(X_valid_B, y_valid_B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d338b226",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 1ms/step - loss: 0.1337 - accuracy: 0.9825\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.13373036682605743, 0.9825000166893005]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_B.evaluate(X_test_B, y_test_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "757661cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 1ms/step - loss: 0.0719 - accuracy: 0.9955\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.07194174081087112, 0.9955000281333923]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_B_on_A.evaluate(X_test_B, y_test_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7f32e574",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.916666666666718"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(100 - 97.05) / (100 - 99.40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117f6b5e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
